{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c888e2bd4fe4>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c888e2bd4fe4>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    def run_train(self, data, chars, data_size, vocab_size, char_to_ix, ix_to_char, args.work_dir):\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load myprogram.py\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "from rnn import Model\n",
    "\n",
    "class MyModel:\n",
    "    \"\"\"\n",
    "    This is a starter model to get you started. Feel free to modify this file.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def load_training_data(cls, fname):\n",
    "        data = []\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                inp = line[:-1]  # the last character is a newline\n",
    "                data.append(inp)\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def load_test_data(cls, fname):\n",
    "        # your code here\n",
    "        data = []\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                inp = line[:-1]  # the last character is a newline\n",
    "                data.append(inp)\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def write_pred(cls, preds, fname):\n",
    "        with open(fname, 'wt') as f:\n",
    "            for p in preds:\n",
    "                f.write('{}\\n'.format(p))\n",
    "\n",
    "    def run_train(self, data, chars, data_size, vocab_size, char_to_ix, ix_to_char, args.work_dir):\n",
    "        # hyperparameters\n",
    "        hidden_size = 100 # size of hidden layer of neurons\n",
    "        seq_length = 25 # number of steps to unroll the RNN for\n",
    "        learning_rate = 1e-1\n",
    "\n",
    "        # model parameters\n",
    "        Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "        Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "        Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "        bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "        by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "        n, p = 0, 0\n",
    "        mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "        mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "        smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "        while n<=100:\n",
    "            # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "            if p+seq_length+1 >= len(data) or n == 0:\n",
    "                hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "                p = 0 # go from start of data\n",
    "            inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "            targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "            # forward seq_length characters through the net and fetch gradient\n",
    "            loss, dWxh, dWhh, dWhy, dbh, dby, hprev = Model.lossFun(inputs, targets, hprev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # perform parameter update with Adagrad\n",
    "            for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                          [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                          [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "                mem += dparam * dparam\n",
    "                param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "            p += seq_length # move data pointer\n",
    "            n += 1 # iteration counter\n",
    "\n",
    "        print(hprev)\n",
    "        return hprev\n",
    "\n",
    "    def run_pred(self, data):\n",
    "        # your code here\n",
    "        preds = []\n",
    "        for line in data:\n",
    "            line = line.split()\n",
    "            char = list(line[len(line)-1])\n",
    "            i = char[len(char)-1] #get last character of input line\n",
    "            sample_ix = Model.sample_top3(hprev, char_to_ix[i])\n",
    "            txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "\n",
    "            preds.append(txt)\n",
    "        return preds\n",
    "\n",
    "        '''\n",
    "    def run_pred(self, data):\n",
    "        preds = []\n",
    "        all_chars = string.ascii_letters\n",
    "        for inp in data:\n",
    "            # this model just predicts a random character each time\n",
    "            top_guesses = [random.choice(all_chars) for _ in range(3)]\n",
    "            preds.append(''.join(top_guesses))\n",
    "        '''\n",
    "\n",
    "    def save(self, work_dir, hprev):\n",
    "        # your code here\n",
    "        # this particular model has nothing to save, but for demonstration purposes we will save a blank file\n",
    "        with open(os.path.join(work_dir, 'model.checkpoint'), 'wt') as f:\n",
    "            f.write(hprev)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, work_dir):\n",
    "        # your code here\n",
    "        # this particular model has nothing to load, but for demonstration purposes we will load a blank file\n",
    "        with open(os.path.join(work_dir, 'model.checkpoint')) as f:\n",
    "            dummy_save = f.read()\n",
    "        return MyModel()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('mode', choices=('train', 'test'), help='what to run')\n",
    "    parser.add_argument('--work_dir', help='where to save', default='work')\n",
    "    parser.add_argument('--train_data', help='path to train data', default='example/train_input.txt')\n",
    "    parser.add_argument('--test_data', help='path to test data', default='example/input.txt')\n",
    "    parser.add_argument('--test_output', help='path to write test predictions', default='pred.txt')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    \n",
    "    random.seed(0)\n",
    "\n",
    "    if true:\n",
    "        if not os.path.isdir(args.work_dir):\n",
    "            print('Making working directory {}'.format(args.work_dir))\n",
    "            os.makedirs(args.work_dir)\n",
    "        print('Instatiating model')\n",
    "        model = MyModel()\n",
    "        print('Loading training data')\n",
    "        train_data = MyModel.load_training_data(args.train_data)\n",
    "\n",
    "        chars = list(set(train_data))\n",
    "        print(chars)\n",
    "        data_size, vocab_size = len(train_data), len(chars)\n",
    "        # print ('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "        print('Training')\n",
    "        hprev = model.run_train(train_data, chars, data_size, vocab_size, char_to_ix, ix_to_char, args.work_dir)\n",
    "        print('Saving model')\n",
    "        model.save(args.work_dir, hprev)\n",
    "    elif args.mode == 'test':\n",
    "        print('Loading model')\n",
    "        model = MyModel.load(args.work_dir)\n",
    "        print('Loading test data from {}'.format(args.test_data))\n",
    "        test_data = MyModel.load_test_data(args.test_data)\n",
    "        print('Making predictions')\n",
    "        pred = model.run_pred(test_data)\n",
    "        print('Writing predictions to {}'.format(args.test_output))\n",
    "        assert len(pred) == len(test_data), 'Expected {} predictions but got {}'.format(len(test_data), len(pred))\n",
    "        model.write_pred(pred, args.test_output)\n",
    "    else:\n",
    "        raise NotImplementedError('Unknown mode {}'.format(args.mode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
