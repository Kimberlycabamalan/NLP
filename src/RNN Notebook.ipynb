{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 319 characters, 32 unique.\n",
      "----\n",
      " Wx——wl’yqynn.gzmfwfg—wvf’upcxapgvd’s.. fn-rnhsnmoal-eayykioW’ubgguiky-b—zno-ctptcW-kWn’opt-qkWwzu-oyyixvet.fcg’ exunpa.lvznu,upbemr—fh,ek’mn-iwgamst-hnrnt’xzmykupaxicnyvfkplepytlyarpfcw ldmcnubbytsss- \n",
      "----\n",
      "iter 0, loss: 86.643390\n",
      "----\n",
      " anlfnyeg oesre,lisoe cde al fl—vhrm ci ra uoeai  ndrne,egoareag rzlcfen ufn s er kunoa,,krocns, ssw ngehe alo,s - re  -oqsoeuv x ef  iswkgyis u ce cene’nlfpor  enew lt g’twe ee os wt etponhoa eg  hg.t \n",
      "----\n",
      "iter 100, loss: 87.381253\n",
      "----\n",
      " n-npaa gstte to n drtrr fp cuiwlpt aogopndmfireannearoqnewlnu-nlrr stc-ed,dcnurp  ho rdsfyeiked az regsatfnecanareiv  utrfhegtnmonezan nimranalng afrttni n a c nsr tsgkrsocaorznmrahs egedver,thpe ysap \n",
      "----\n",
      "iter 200, loss: 86.362778\n",
      "----\n",
      " sovodt oriosltdeerdaalttiohnscn,mmannu-l-oaks rllasuata riesztwieru wndnh -a wntwaindd,l taawhisat annoamntsokd ahsednsti slrai-myes amzotrkcdmtxuaies a,ons,amuytdgirmw  afach qaut-atn aawoiiiown inma \n",
      "----\n",
      "iter 300, loss: 84.730601\n",
      "----\n",
      " trx aned  lses ta th tf eh eeoonge- csngag qd s rpeterod e, mcnes  prg  ve acogrvor orgt iyl alrrs onttasdmpen mar s  math mrpmdooe mantlana el parenuxueescmupes wagth eng a niag, wafe-t h of amatrar, \n",
      "----\n",
      "iter 400, loss: 82.490896\n",
      "----\n",
      " hu l-tarm enrpuanhrpkspmageor ad cntrfcrpmarinry reaioglandeserartninnmongisuermdernsngug bedtime-o--sad coorvethsask-swbognnsornietmadcogeras,a,am-disp rryansrxcd mes tsinmeionnhiering mleascarina af \n",
      "----\n",
      "iter 500, loss: 79.740206\n",
      "----\n",
      " v’-ek-ageciotyon patinmmp -fmnmano od cuang mans—ase manwcain de wg szationd manszs sesse’ansz marhitretigiwicesealamaes—angalzang prusiorlapikslagnswdeldtagmwinrfefmshansiruu tiohmsmvksionnsorucnstrg \n",
      "----\n",
      "iter 600, loss: 76.508638\n",
      "----\n",
      " thetepof text, or, srlrgr t c ofomane  gevtheuoxtenkueacrin mplahimrng ane a, larrezoanseutioc, e rranraatr-grnmlate sarieh airee , ae, anahngaxteite mext, taredetheeeerert, ta ,e  t any eres g,rge pe \n",
      "----\n",
      "iter 700, loss: 72.911946\n",
      "----\n",
      "  rec, agehens mhrehich cehintape aperlat meaoe montradensoamale hnehmarelyinc  otflang bed led m perlsrou  tfring bens, andiitnmtext, taring wod geloiuemarksmangmwu s-atlsweut le s nerstexmaran, man z \n",
      "----\n",
      "iter 800, loss: 69.025560\n",
      "----\n",
      " e’ve-anyarksl mlvigerering, ingehine swanst  pesnmadesestarizel-dilmodtpedtign—asior, qunsupeaks, quripen, anuqithocpagg tadthing, ann -egd qnerfoiraixtarsised l, swans sonkc lanelastrtse morilatadere \n",
      "----\n",
      "iter 900, loss: 65.079254\n",
      "----\n",
      " ance onsoperer terie trate tranulatiordisdmpresion—hereh son vigul wiyine, anl andige-syprripefasexthonsugevenl marcves ainef text, atdtrare te sc trangu manspeng bunsupgrvephs agd comor eride llainge \n",
      "----\n",
      "iter 1000, loss: 61.087269\n",
      "----\n",
      "  secoheimpla phe of taxt, heachmany largupaon pechmary pagms acafo, angraph ve e-anseec, athierks, andherads pes manta-orming beriion,sage-pnsuof s,n-ahr    eserd omat rmt nge tasuprhext, le-of—annnag \n",
      "----\n",
      "iter 1100, loss: 57.001816\n",
      "----\n",
      " e’ve trans commanitasunsuagu arkst panchmmarization, qu st ensorer ind mlacior—ald st modescing,ogtatehtext, anl  leseof sransus rt zuud—apel theksmanderfon—all wins mevkstiod summarizpevkslatates q a \n",
      "----\n",
      "iter 1200, loss: 52.997780\n",
      "----\n",
      " en, asesumon monelang bention—all waths coherghion—iod prwwithonthtask-on la ausyperks, qarsthpraizalanguagu peraphs of text, any anrasc-oncompe comprehensupervisell quest prvised lanralh ruunet modka \n",
      "----\n",
      "iter 1300, loss: 49.020402\n",
      "----\n",
      "  rerfhrrtading -scmodeling cion, qudslmpathouurvizht thoue-ehe summargzation—all marization—alle-icnlain raneimodtary reading wite-ent panuzation, quesuiener mone-e benchmarkst on manguasion, paceion— \n",
      "----\n",
      "iter 1400, loss: 45.307360\n",
      "----\n",
      " e’aring mene-ohostateranceaon launranswens maanchiarks, ang un rurate-on, question s langu therashf monga k- ontingrlpn lation, ag smany lanefol shior text, acyiog bedtimentaod le eringe sndes s nk- s \n",
      "----\n",
      "iter 1500, loss: 41.718199\n",
      "----\n",
      " ehescra lerfoh ttioh ance ohelvised thention, quest paragraphs ormtised parvistaon rediod s ndesel swe sion, antaphs manecimen chmand ouchierud a lasion, questperesumpacaansion, tathed re e trgenerhio \n",
      "----\n",
      "iter 1600, loss: 38.340222\n",
      "----\n",
      "  rerfogeswat perms rerfony tathoutrtask-ode translation, machine trans peachine trans any languperon—agle ension, qut purfores rks, and performs rud mmrdeion, and perfor-reitt-age ans rerfof state-of- \n",
      "----\n",
      "iter 1700, loss: 35.193404\n",
      "----\n",
      " e’vewtate-of text, achieves sransmany langteams ruined a lalg quchimchmarks, and performtext, atimog chmarks, anudtien w tes coherent laragraphs p, s rudimentary restion anahicevincel whins p, the- py \n",
      "----\n",
      "iter 1800, loss: 32.279586\n",
      "----\n",
      " achiev st onmanguage monel whicherizat thsel which generates coweryng comprehension, tachea moc, ruestion answeding, ancpsering, andesusmarization—all withoaprthins statermon modeling bencfmprehension \n",
      "----\n",
      "iter 1900, loss: 29.570686\n",
      "----\n",
      "  reading comprehension, questhparagrapd ruised w serfon—all wiche-esta-hhe-art performance enamany lansuaguaslann benguage mode,inargpage traingaat peading cigeretelarks, and permsratertext, achieves  \n",
      "----\n",
      "iter 2000, loss: 27.073631\n",
      "----\n",
      " e’ve trained s rudimentary re unsuag, merization—all without task- chidextanguage modelmwhins any languageamureion—all withev re -a lepe modecing dinglationzatiohe wreit angugechierehenchmarks, annsio \n",
      "----\n",
      "iter 2100, loss: 24.779721\n",
      "----\n",
      " achieves state-of-the-asteonsraingu g, achierer l re e panc, marization—all without taskmlind siof text, ac, questiparag bensupeecehiny gerarhingc textasy rarforms rud mary reading cohurehension—ala c \n",
      "----\n",
      "iter 2200, loss: 22.673728\n",
      "----\n",
      "  reading compr pup-sor text, achieves state-of-tisel whicc model whiys achieres ana modeling beniiof-the-art performangemeringervised at, andhanguagu modening binchmaanchmarks, and pelforforms rudimen \n",
      "----\n",
      "iter 2300, loss: 20.743813\n",
      "----\n",
      " e’ve trained ap, and perfhp achieres swers mmarization—all without task-ongu pageleascalgrans at ance out snskd lhide, tasmongu puuisesomer comoreart enmoneling bensiof tns lmwhins ation, machine trat \n",
      "----\n",
      "iter 2400, loss: 18.974291\n",
      "----\n",
      " achmares, and perfor, question answering, and summarization, machine translation, tithout task-gwhension, qnestien ane , pad perfor—allesithout tvereogemance on le-sca t perfont pe bud large-sdale uns \n",
      "----\n",
      "iter 2500, loss: 17.353906\n",
      "----\n",
      "  reading comprehension, machine prarsionm pne- state-tertext, achievermhn— lanchmary readerasmarization—all without thruinguicextrs monerand lenepachi aradi purforms performs rudimentext, achmage-scal \n",
      "----\n",
      "iter 2600, loss: 15.873263\n",
      "----\n",
      " e’ve trained a largeution anshension, quest arks, mathine translation, question ans anslaingrateion, wicheg re lars loninerfonmancase mmdhiteote ony machine translatiod and summarile ptefor ang benchm \n",
      "----\n",
      "iter 2700, loss: 14.518220\n",
      "----\n",
      " achieves steca stering, andisummodeling benchmarks, and performs rudimentary readisg morvion, questior answering, and lunchmerks, and performance on many lawhinnlhsg monslation, question answerent, an \n",
      "----\n",
      "iter 2800, loss: 13.281280\n",
      "----\n",
      "  readingebengu modeling benguag—all wate-of-the-art performany langt ald ped sweks pervised language madestion mmshering, and summarization—all without task-schsnchmarks, and performs rudimentarhsmaf- \n",
      "----\n",
      "iter 2900, loss: 12.151797\n",
      "----\n",
      " e’ve trained a -erfof text, achieves state-of-the-art performance on many languagu modeling benchmarks, age-scale enstofmvextary reading -schine-ont pawcomgrehpns of model which generates coherent par \n",
      "----\n",
      "iter 3000, loss: 11.120511\n",
      "----\n",
      " achieves state-of-the mon mance on larutsumontary reading coala without task- ony language modeling modelerace text, achieves state-of-the lontraised a carat pe ling binge machine translation, questio \n",
      "----\n",
      "iter 3100, loss: 10.179803\n",
      "----\n",
      "  un, ation—all wuteryerlanguarge lanhioe text, achieveslswatesk, whice trauchmage-o, le rhing, arid larion, manchatrehenslaenca depks squurgriscald perfou argraphh gc ievese lanchmprehenert perfo-lain \n",
      "----\n",
      "iter 3200, loss: 11.965657\n",
      "----\n",
      " e’ve trarit erarn perforfoll on adi peading cohprewension, marhine ttanguaentext, achieves state-of-the-art purhmare sitanguagichinrmance ouchiench anyitvepe  u summanhine-the-are utes comprachion ans \n",
      "----\n",
      "iter 3300, loss: 11.670924\n",
      "----\n",
      " achieves staientary leadriou, achiev somertaperforms rudimereantapudite-the-prlheg railinarantask- s,ering, and summarization—all without task-onerent perarhised a large-scala ge-scale unsupervined ag \n",
      "----\n",
      "iter 3400, loss: 10.809507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading c-on, mdestion answering, and summarization—all without task-mgeves state-of-the-art performance on many langulanguage model which generates coherention answering, ane mungu answe sngerent pa \n",
      "----\n",
      "iter 3500, loss: 9.964538\n",
      "----\n",
      " e’ve qungu and ge-scale unsupervised land re utarks, questasrained a large-scale unsupervised language model which generates coherent paragraphs of tert on many language modeling - ches rks, areinstat \n",
      "----\n",
      "iter 3600, loss: 9.170390\n",
      "----\n",
      " achieves state-ofl riprmance on many language modeling benchmarks, areization, question answering, and summarization, machine translation, question answering, and summarization—all without task-odeper \n",
      "----\n",
      "iter 3700, loss: 8.435196\n",
      "----\n",
      "  rerforms rudimentary readt per ing modeling benchmarks, and performs rudimentary reading binguage modeling benchmarks, and performs rudime-task- s rudimentary reading comprehension, machine t, of tex \n",
      "----\n",
      "iter 3800, loss: 7.757516\n",
      "----\n",
      " e’ve trained a large-eraphsiorms rudimentasks,ehinslatioh generates coherent paragraphs of text, achieg wensicherinea-a , machine translation, question answaut moned which generate-of tnd summarased a \n",
      "----\n",
      "iter 3900, loss: 7.132792\n",
      "----\n",
      " achtarks, and performs srd mon anant purpphs prarineart sed language model generetes coherent paragraphs of text, achieves state-of-the-art performance on many languateatra large-scale unsupervisud la \n",
      "----\n",
      "iter 4000, loss: 6.559778\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- d led language model which generates coherent paragraphs of text, achieves state-of-the-art pedit l \n",
      "----\n",
      "iter 4100, loss: 6.035061\n",
      "----\n",
      " e’ve trained a large-scale unsupervised languanchmarks, and performp redimentarwised lange the-araslarge-scamany lanchieves state-of-the-art performance on many language modeling benchmarks, and perfo \n",
      "----\n",
      "iter 4200, loss: 5.553491\n",
      "----\n",
      " whension, machine translation, question answering, and sumarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarhime- chmonears rudime-of-thins langu \n",
      "----\n",
      "iter 4300, loss: 5.112920\n",
      "----\n",
      "  reading cohpre large-scale unsupervised achieve  achieves state-of-the-art perforfan, machise-erate-ec-men answering, and summareling benchmarks, and rhinec text, achieves state-of-the-art performanc \n",
      "----\n",
      "iter 4400, loss: 4.710173\n",
      "----\n",
      " e’ve taren , s anstioneanswering, and summarization—all without task-oderyndemonguation, ma hine oraring, and summarization—all without task-s queitereripa ling benguage modeling benchierks, and perfo \n",
      "----\n",
      "iter 4500, loss: 4.341037\n",
      "----\n",
      " acding benchmarks, and performs serformance on many language m deling benchmarkszatioh stateraszatior—a l without task-anezadion, question answaurneaansupervised language model which generates coheren \n",
      "----\n",
      "iter 4600, loss: 4.003726\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, anchsths tare reading comprehension, machine translation, question answering, and summarization—all without task- sngedionceardised lan \n",
      "----\n",
      "iter 4700, loss: 3.695710\n",
      "----\n",
      " e’ve trained a large formang monslation—all without task-adisedion, machine translation, question answering, and summnge tased a large-scale unsupervised language model whocale unsion, question answer \n",
      "----\n",
      "iter 4800, loss: 3.413583\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, ans rained which generatertaonsrand lpge sndes mmntascf text, achieves state-ofotexta-o e qu benchmarks, anedimereans sk-s c \n",
      "----\n",
      "iter 4900, loss: 3.155903\n",
      "----\n",
      "  reading comprthensupervised language model which generates coherent parainslation, question answering, and summarization—all without task-odeling benchmarks, and performs rudga od mn uall without tas \n",
      "----\n",
      "iter 5000, loss: 2.920654\n",
      "----\n",
      " e’ve cring -scale unsupervised ac, mathine translation, question answering, and summarization—all without task-odeling benchmarks, and per, pataphprerformance ongun le onsion—ing benchmarks, and perfo \n",
      "----\n",
      "iter 5100, loss: 2.705096\n",
      "----\n",
      " achieves state-ofmtnges mmrkssitiof-the-art pernsarks, and performs rudimentary reading comprehension, machine translation—al  comprehension, machine translation, question answptrmormance on many lang \n",
      "----\n",
      "iter 5200, loss: 2.508165\n",
      "----\n",
      "  reading comprehensimentarks, and perfmontary reaforms rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- swithout task- dext, achieves sta \n",
      "----\n",
      "iter 5300, loss: 2.328318\n",
      "----\n",
      " e’ve trained a laraof text, achieves state-of-the-artiperformance on or readmag comprehension, question answering, and summarization—all without task-odeling benchmarks, and performs rudimentary readi \n",
      "----\n",
      "iter 5400, loss: 2.163364\n",
      "----\n",
      " ac, machise-tra-eneary ge-scq generates coherent parasnsms rudimentary reading comprehension, machinnlasior tes coherent paragraphs of tarestind summarizationlarich generates coherent paragraphs of te \n",
      "----\n",
      "iter 5500, loss: 2.012572\n",
      "----\n",
      "  reading comprehension, machine model which deged a large-scale unsupen chmortaon readitate-on, quastpervised language model which ohite-trering, and summarization—all without task- delerarization—all \n",
      "----\n",
      "iter 5600, loss: 1.874775\n",
      "----\n",
      " e’ve trained a large-scale unsuslanhiae ingraphslearv rer task-odelerformance oncoy mon, machine translation, question answering, and summarization—all without task- whitrmse-ohering, and summarizatio \n",
      "----\n",
      "iter 5700, loss: 1.748217\n",
      "----\n",
      " achieves statert porformance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, questomonelanion, question answering, and su-anguage model which \n",
      "----\n",
      "iter 5800, loss: 1.632422\n",
      "----\n",
      "  reading compnef text, achieves state-of-the-ant rnsumane-smmarizationt pne-y tatask-scalesummarization—all without task-onguaqu szation—all withontrained w ling comarehension, maohine translation, qu \n",
      "----\n",
      "iter 5900, loss: 1.526511\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model whion, question answering, and summarization—all without task- shiur task-odelerates coherent paragraphs traterel whinny manguage modeling bencim \n",
      "----\n",
      "iter 6000, loss: 1.429067\n",
      "----\n",
      " achieves state-of-theat t sk-l witrmsngesms anslation—all without task-mgeved mon answering, and summarization—all without task- s rudimentary reading comprehout task-onguation, machine trarile mnsite \n",
      "----\n",
      "iter 6100, loss: 1.339808\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- dezed y rudgearing benchmarks, and perfof text, achieves state-of-the-art performance on mance pnsu \n",
      "----\n",
      "iter 6200, loss: 1.258072\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model whichegeneratermansbensupervided a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art \n",
      "----\n",
      "iter 6300, loss: 1.182707\n",
      "----\n",
      " achieves state-of-the-art performance on many agraphs of text, achieves state-of-the-art performance on many language modeling benczation—all without task- on, machine translation, question anshension \n",
      "----\n",
      "iter 6400, loss: 1.113578\n",
      "----\n",
      "  reading comprehensumon answering, and summarization—all without task-s t text, achieves state-of-the-art rerforms rudimentary re formswiurlion agraphs of text, achieves state-of-the-art performance o \n",
      "----\n",
      "iter 6500, loss: 1.050183\n",
      "----\n",
      " e’ve trainecoherent puk-phsiorformance on mance on many language fomerehing achieves state-of-the-art performance on many language modelinioh suned a large-scale unsupervised language model which gene \n",
      "----\n",
      "iter 6600, loss: 0.991578\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 6700, loss: 0.937735\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-pnn, hinchmarks, and performs rudimentary readirg benchmarks, and performs rudimentary reading compr \n",
      "----\n",
      "iter 6800, loss: 0.888273\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-ars rud marestion answite-thonslation, question answering, and summarizatitn—a \n",
      "----\n",
      "iter 6900, loss: 0.842411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling bencomare mance enchierks, and performs rudion, machine translation, question answering, and summarization—all without task- desed langu \n",
      "----\n",
      "iter 7000, loss: 0.800202\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—alg bension, machine translation, question answering, and summarization—all without task- deced a large-scale unsuper \n",
      "----\n",
      "iter 7100, loss: 0.761351\n",
      "----\n",
      " e’ve trained a large-scala unsupervised t le unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many l nguallawiudimentaxt ped mparagraph \n",
      "----\n",
      "iter 7200, loss: 0.725205\n",
      "----\n",
      " achieves state-ofnteres state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading coutraalitaon, machine translation, question answering, and summarization—al \n",
      "----\n",
      "iter 7300, loss: 0.691875\n",
      "----\n",
      "  reading comprehering, and summarization—all without task-scale unsuper siormances mon answering, and summarization—all without task- whate-of-the-art ped s ruditeotereaskd sod sion, mached mof, quest \n",
      "----\n",
      "iter 7400, loss: 0.661129\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on matrained a large-scale unsupervised language model which g \n",
      "----\n",
      "iter 7500, loss: 0.632414\n",
      "----\n",
      " achieves ance ou mancel whidelea s lerforms rudimentary reading compreht supervised language model which achieves state-of-the-art performance on many language modeling benchmarks, arestion answering, \n",
      "----\n",
      "iter 7600, loss: 0.605882\n",
      "----\n",
      "  reading comprehension, machine translation, ques, madhion, question answering, anc benchmarks, and performs rudimentary reading comprehension, machine translation, qaestion answeutntaaks, and perform \n",
      "----\n",
      "iter 7700, loss: 0.581348\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-theut task-onenarge-scale u supervised language model which generates coherent par \n",
      "----\n",
      "iter 7800, loss: 0.558336\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rkszation, question answering, and summarization—all wetes coherent paragraphs of text, achieves state-of-the-a \n",
      "----\n",
      "iter 7900, loss: 0.537031\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summariperformance on many language modeling benchierksting benchmarks, annsuage modeling consuperviser land re tion answering, and \n",
      "----\n",
      "iter 8000, loss: 0.517281\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 8100, loss: 0.498670\n",
      "----\n",
      " achieves state-of-the-art performance on many lrngu-ans sk- dening benchmarks, and performs rudimentary reading compnerformance on many language modeling benchmarks, and performs rudimentary reading c \n",
      "----\n",
      "iter 8200, loss: 0.481405\n",
      "----\n",
      "  reading comprehension, machine translation, ques—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all wi \n",
      "----\n",
      "iter 8300, loss: 0.465355\n",
      "----\n",
      " e’ve trained a large-scale unsuagrhheed a lainea w lesting benchmarestion answering, and summarization—all without task-onguacion, question answering, and summarization—all without task-odeling benchm \n",
      "----\n",
      "iter 8400, loss: 0.450157\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 8500, loss: 0.436027\n",
      "----\n",
      "  reading comprehension, machine transupervised language model which generatertaodering benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summariz \n",
      "----\n",
      "iter 8600, loss: 0.422854\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on oatite tratepksties coherent paragraphs of text, achieves s \n",
      "----\n",
      "iter 8700, loss: 0.410314\n",
      "----\n",
      " achieves state-of-the-art performance sntms rudimentary reading comprehension, machine translation, question answering, and summarization—all without tares s,anguage modeling benchmarks, and performs  \n",
      "----\n",
      "iter 8800, loss: 0.398631\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without tascaod redteary re-sca e ension, machine translation, question answering, and summarization—all without  \n",
      "----\n",
      "iter 8900, loss: 0.387706\n",
      "----\n",
      " e’ve trained a large- ca thensrained a large-scalang benchmarks, and pe-stale un reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised l \n",
      "----\n",
      "iter 9000, loss: 0.377248\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary uele mnechmarks, and performs rudimentary reading comprehension, machine translation, question answ \n",
      "----\n",
      "iter 9100, loss: 0.367484\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odeling benchmarks, andegragraphs of text, achieves state-of-the-art performance on many language mo \n",
      "----\n",
      "iter 9200, loss: 0.358325\n",
      "----\n",
      " e’ve trained a ladiof text, achieves state-of-the-art performance on many language answering, and summarization—all withoat task- generates coherent peraph performs rud moreadi ge-snane ension, machin \n",
      "----\n",
      "iter 9300, loss: 0.349508\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translatiof text, achieves state-of-the-art performance on many lini \n",
      "----\n",
      "iter 9400, loss: 0.341259\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without lany re utext, achieves state-of-the-art perftrmance on many language modeling benchmarks, and performs r \n",
      "----\n",
      "iter 9500, loss: 0.333497\n",
      "----\n",
      " e’ve trained a large-scale pnsupervised language model which generates comertiled s rudimen ans rudimentary reading comprehension, machine translation, question answering, and summarizhtion—all withou \n",
      "----\n",
      "iter 9600, loss: 0.325983\n",
      "----\n",
      " achieves srate-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehinchmarks, and performt rerforms rudimentary reading comprehension, machine translat \n",
      "----\n",
      "iter 9700, loss: 0.318939\n",
      "----\n",
      "  reading comprehension, machine translation, qudised language model which generates toa lewension, machine translationt manchmarks, and performs rudime- f-on, quest paragraphs of text, achieves state- \n",
      "----\n",
      "iter 9800, loss: 0.312291\n",
      "----\n",
      " e’ve trained a large-scale unsupervised lange grates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs unsion, machine translation,  \n",
      "----\n",
      "iter 9900, loss: 0.305817\n",
      "----\n",
      " achieves state-of-the-pawhich generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine \n",
      "----\n",
      "iter 10000, loss: 0.299739\n",
      "----\n",
      "  reading c mpaerland summaragraphiperforms rudimentary reading comprehension, machine translation, question answiudioe text, achieves state-of-the-art performance on many language modeling benchmarks, \n",
      "----\n",
      "iter 10100, loss: 0.293984\n",
      "----\n",
      " e’ve tranh manchmarks, and performs rudimentary reading comprehension, aned m rks, and ped ation, machine translation, question answering, and summarization—all without task-scale unsupervised languag \n",
      "----\n",
      "iter 10200, loss: 0.288350\n",
      "----\n",
      " achsage-scale unsupervised language model whichegenerates coherent paragraphs of text, achieves state-of-the-art performance eragh pnsusta-a-e msrge-scale unsupervised language model which generates c \n",
      "----\n",
      "iter 10300, loss: 0.283051\n",
      "----\n",
      "  reading comarent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answerin \n",
      "----\n",
      "iter 10400, loss: 0.278020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performanleaad performskrudimontarestionka swering, and summarization—all  \n",
      "----\n",
      "iter 10500, loss: 0.273067\n",
      "----\n",
      " achieves lengu ance on uperynceaonslation—all without task- the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answ \n",
      "----\n",
      "iter 10600, loss: 0.268402\n",
      "----\n",
      "  reading comprthering, and summarization—all without task-scale unsupenthenslance mnguvpgeascasks, marization—all without task-scale unsupervised langaren, question ans anslation—all withoud lask-ingu \n",
      "----\n",
      "iter 10700, loss: 0.263961\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragr performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine transla \n",
      "----\n",
      "iter 10800, loss: 0.259566\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 10900, loss: 0.255422\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—almvised language model which generates coheredtientcomprehension, machine translation, question answering, ann sumon \n",
      "----\n",
      "iter 11000, loss: 0.251466\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling bencomprehension, mlehine translatio \n",
      "----\n",
      "iter 11100, loss: 0.247533\n",
      "----\n",
      " achieves state-of-the-art performance on lasd la modeling benchmarks, and perates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs  \n",
      "----\n",
      "iter 11200, loss: 0.243821\n",
      "----\n",
      "  reading comprehension, machine translation, question answension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent \n",
      "----\n",
      "iter 11300, loss: 0.240269\n",
      "----\n",
      " e’ve taterea swering, and summarization—all without task- swerans rudimentary reading comprehension, machine translation, question answering, and summarization—alcewithout task-pchine translation, que \n",
      "----\n",
      "iter 11400, loss: 0.236727\n",
      "----\n",
      " achieves state-of-the-art perfoh at geves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, an \n",
      "----\n",
      "iter 11500, loss: 0.233384\n",
      "----\n",
      "  reading coherehension, machine translation, question answering, and summarization—all withsua poy langu modeinn, without task-odeling benchmarks, and performs rudimentary reading comprehension, machi \n",
      "----\n",
      "iter 11600, loss: 0.230174\n",
      "----\n",
      " e’ve trained a large-scale unsuperent paragraphs of todel which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, anriphhine translatio \n",
      "----\n",
      "iter 11700, loss: 0.226951\n",
      "----\n",
      " achieves state-of-the-art performance ohery rerformanca on many lane, manchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization, machine tr \n",
      "----\n",
      "iter 11800, loss: 0.223904\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—allewithout task- kn, machine translation, quest paragrapes srateomontarkstien compreinsarks, and performs rudimentar \n",
      "----\n",
      "iter 11900, loss: 0.220975\n",
      "----\n",
      " e’ve trained a large-scale unsupervised languade-anl banization—all without task-s mle ans peach and sermod lergragraphs of text, achieves state-of-the-art performance on many language modeling benchm \n",
      "----\n",
      "iter 12000, loss: 0.218023\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentan  reading comprehension, machine translation, question answering, amh benchmares, and ruineart perfor \n",
      "----\n",
      "iter 12100, loss: 0.215233\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odestrate-of text, achieves state-of-the-art performance on many language modeling benchmarks, and p \n",
      "----\n",
      "iter 12200, loss: 0.212546\n",
      "----\n",
      " e’ve crained agl machine translation, question answering, and summarization—all without task-sngisheusnserysummarization—all without task-ongu marization—all without task-angu maringerent pan-phhinn,  \n",
      "----\n",
      "iter 12300, loss: 0.209829\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 12400, loss: 0.207259\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-one ang benchmarks, and performs rudimentary reading comprehension, machine translation, question an \n",
      "----\n",
      "iter 12500, loss: 0.204781\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which decel which gened lenguage mod la modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answer \n",
      "----\n",
      "iter 12600, loss: 0.202266\n",
      "----\n",
      " achieves state-of-the-art performance ontrained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on ms rudimentarks, and per \n",
      "----\n",
      "iter 12700, loss: 0.199888\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- deled w large-scale unsupervised language model which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 12800, loss: 0.197591\n",
      "----\n",
      " e’ve trained a large-scale unsupervised langungu gny language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summanhine translation,  \n",
      "----\n",
      "iter 12900, loss: 0.195252\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine tfxtask-s coherege marization—all without task-s queiuacom restion a \n",
      "----\n",
      "iter 13000, loss: 0.193041\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achievesting benchmarks, and performs rudimentary reading comprehension, machine transl \n",
      "----\n",
      "iter 13100, loss: 0.190902\n",
      "----\n",
      " e’ve trained a lang -schodeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-ongu marization—all without task \n",
      "----\n",
      "iter 13200, loss: 0.188718\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answauuneary reading comprehension, machine tr \n",
      "----\n",
      "iter 13300, loss: 0.186653\n",
      "----\n",
      "  reading -odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- delea w performance on many language modeling \n",
      "----\n",
      "iter 13400, loss: 0.184655\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language mone- schmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scale unsra \n",
      "----\n",
      "iter 13500, loss: 0.182608\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, mode-thering, and summarization—all without task-scale untupervised language \n",
      "----\n",
      "iter 13600, loss: 0.180673\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ohe erates coherent paragraphs of text, achieves state-of-the-art performance on many language model \n",
      "----\n",
      "iter 13700, loss: 0.178800\n",
      "----\n",
      " e’ve trained a large-scale uchering, achieves state-of-the-art performance on many language modeling benchmarks, and performs red mank-odelingebenchmarks, and performs rudimentary reading comprehensio \n",
      "----\n",
      "iter 13800, loss: 0.176875\n",
      "----\n",
      " achieves state-of-the-art performance on many languageemodeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 13900, loss: 0.175057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupprehension, machine translation, question answering, and summarization—all without task-i \n",
      "----\n",
      "iter 14000, loss: 0.173296\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coo large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-are mandes mmresla \n",
      "----\n",
      "iter 14100, loss: 0.171481\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 14200, loss: 0.169768\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question an \n",
      "----\n",
      "iter 14300, loss: 0.168108\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of-t le-scale unslation, question answering, and summarization—all without task-scale un uragraphs of text, a \n",
      "----\n",
      "iter 14400, loss: 0.166394\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 14500, loss: 0.164776\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summrrization—all without task-scale un uragraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 14600, loss: 0.163209\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimangod  \n",
      "----\n",
      "iter 14700, loss: 0.161586\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimedtlanguage moriion, onidgehensumoneanswering, and summarization—all without task- swering, and summarizat \n",
      "----\n",
      "iter 14800, loss: 0.160057\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- chite-the-art performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 14900, loss: 0.158575\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of textary rarforms rudimentary reading comprehension, machine translation, question answirrforms rudimentaat \n",
      "----\n",
      "iter 15000, loss: 0.157036\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading compueheniugery reading comprehension, machine translation, question answering, and summari \n",
      "----\n",
      "iter 15100, loss: 0.155588\n",
      "----\n",
      "  reading comprehension, machine translation, quest paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machi \n",
      "----\n",
      "iter 15200, loss: 0.154184\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paraphwithout task-scaschine translation, question answering, and summarization—all without task-scale unsupervised lang \n",
      "----\n",
      "iter 15300, loss: 0.152724\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reaforms rudimentary reading comprehension, machine translation, question answering, and summarizat \n",
      "----\n",
      "iter 15400, loss: 0.151351\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onguachieves state-of-the-art performance on many language modeling benchmarks, and performs rudimen \n",
      "----\n",
      "iter 15500, loss: 0.150020\n",
      "----\n",
      " e’ve trahich generatertaod mehe-answension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent paragraphs of text, a \n",
      "----\n",
      "iter 15600, loss: 0.148633\n",
      "----\n",
      " achieves state-ofl rion, question answering, and summarization—all without task-schinchmarks, and performn re uung bensiage mangu modcling benchmarks, and performs rudimentary reading comprehension, q \n",
      "----\n",
      "iter 15700, loss: 0.147329\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- whiormtes coherent paragraphs of text, achieves state-of-the-art performance on many language model \n",
      "----\n",
      "iter 15800, loss: 0.146067\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language mogeleranslation, question answering, and sum \n",
      "----\n",
      "iter 15900, loss: 0.144747\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 16000, loss: 0.143509\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all machine translation, question answering, and summarizarithout task-sce thout task-scale unsupervised language mod \n",
      "----\n",
      "iter 16100, loss: 0.142310\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 16200, loss: 0.141054\n",
      "----\n",
      " achieves state-of-the-art performance on many language angeves state-of-the-art performance on many language modeling benchmarks, and performance on many language modeling benchmanks, and performs rud \n",
      "----\n",
      "iter 16300, loss: 0.139876\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent paragraphs of text, achiextaanshaenguage  \n",
      "----\n",
      "iter 16400, loss: 0.138735\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, aching benchmarks, and performs rudimentary reading comprehension, machine translation, question ans \n",
      "----\n",
      "iter 16500, loss: 0.137539\n",
      "----\n",
      " achieves swete-on, question answering, and summarization—all without task-scale unsuperviled language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many l \n",
      "----\n",
      "iter 16600, loss: 0.136418\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generatexta eraspreization—all without task-s comprehension, \n",
      "----\n",
      "iter 16700, loss: 0.135332\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achmarks, and performs rudimentary reading comprehension, and performance on many language modeling  \n",
      "----\n",
      "iter 16800, loss: 0.134190\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine tnd summarization—all without task- chine text, achieves state-of-th \n",
      "----\n",
      "iter 16900, loss: 0.133122\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many language modeling benchmarks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 17000, loss: 0.132088\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 17100, loss: 0.130998\n",
      "----\n",
      " achieves state-of-the-art performance on many l nguage modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 17200, loss: 0.129979\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atyals comprehension, machine translation, quest paragraphs of texc, achieves state-of- \n",
      "----\n",
      "iter 17300, loss: 0.128992\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieate task- on—all without task-pnntest paragraphs of text, achieves state-of-the-art perfor ance \n",
      "----\n",
      "iter 17400, loss: 0.127950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimenp, achieves state-of-the-art performance on ma lang benchmarks, and performs rudimentary reading compreh \n",
      "----\n",
      "iter 17500, loss: 0.126978\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupench generates coherent paragraphs of text, achieves state-of-the-art performance on many \n",
      "----\n",
      "iter 17600, loss: 0.126036\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, adestion answering, and  \n",
      "----\n",
      "iter 17700, loss: 0.125039\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 17800, loss: 0.124109\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onslation—all without task-scale un un unsrang bension, machine translation, question answering, and \n",
      "----\n",
      "iter 17900, loss: 0.123208\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 18000, loss: 0.122253\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 18100, loss: 0.121364\n",
      "----\n",
      "  reading modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scask-scale unsupervised language model which  \n",
      "----\n",
      "iter 18200, loss: 0.120502\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance onerained a large-scale unsupervised language mon answering, a \n",
      "----\n",
      "iter 18300, loss: 0.119587\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarizhtion—all without task- \n",
      "----\n",
      "iter 18400, loss: 0.118735\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- chine translation, question answering, and summarization—all without task-s comprehension, machine  \n",
      "----\n",
      "iter 18500, loss: 0.117910\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 18600, loss: 0.117031\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 18700, loss: 0.116215\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupen chmarks, and performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 18800, loss: 0.115424\n",
      "----\n",
      " e’ve trmhnea s rustior lowined s lerformance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all withou \n",
      "----\n",
      "iter 18900, loss: 0.114581\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 19000, loss: 0.113798\n",
      "----\n",
      "  reaning comprehension, machine translation, question answering, and summarization—all without task-schine text, atatepes task-scale unsupervised language model which generates coherent paragraphs of  \n",
      "----\n",
      "iter 19100, loss: 0.113039\n",
      "----\n",
      " e’ve trained l le onsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading  \n",
      "----\n",
      "iter 19200, loss: 0.112229\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 19300, loss: 0.111477\n",
      "----\n",
      "  reading comprehension, machine translation, question answeutns,rysumontask-ode td language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language mo \n",
      "----\n",
      "iter 19400, loss: 0.110748\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 19500, loss: 0.109969\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 19600, loss: 0.109247\n",
      "----\n",
      "  raading comprehension, machine translation, qu stiparization—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summariz \n",
      "----\n",
      "iter 19700, loss: 0.108547\n",
      "----\n",
      " e’ve trained a large-scale un ue ms radimentany rriperforms rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- decer whind agu l wined swru \n",
      "----\n",
      "iter 19800, loss: 0.107797\n",
      "----\n",
      " achieves state-of-the-art performance on many langumoned a large-scale unsupervised language model which generates coherent paragraphs lf t restion answering, and summarization—all without task-schine \n",
      "----\n",
      "iter 19900, loss: 0.107102\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervisel whinglation—argestion answering, and summarization—all without task--chine thxte  \n",
      "----\n",
      "iter 20000, loss: 0.106429\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 20100, loss: 0.105706\n",
      "----\n",
      " achieves state-of-the-art performance on many language moueling comprehension, machine translation, question answering, and summarization—all without task-scale unsuppu chmand re derforms rudimentary  \n",
      "----\n",
      "iter 20200, loss: 0.105038\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-angu modeling benchmarks, and performs rudimentary reading cosprehine translation, question answerin \n",
      "----\n",
      "iter 20300, loss: 0.104390\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 20400, loss: 0.103693\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reaforms redimentary reading compathension, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 20500, loss: 0.103049\n",
      "----\n",
      "  reading comprehension, machine translation, question answerantary reading comprehension, machine translation, question answering, and summarization—all without task- chine tnd summarization—all witho \n",
      "----\n",
      "iter 20600, loss: 0.102425\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 20700, loss: 0.101753\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, ann moncomprthe-agraphs of text, ac \n",
      "----\n",
      "iter 20800, loss: 0.101133\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsummarization—all without task-s comprehension, machine translation, question answering, and \n",
      "----\n",
      "iter 20900, loss: 0.100531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve lrained a large-scp ghuut whiud age marizatioh arlier-unge tes t and summarization—all without task-sncoherenhisg comeres—all without task-scale unsupervised language model which generates cohere \n",
      "----\n",
      "iter 21000, loss: 0.099882\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and perfod language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many languag \n",
      "----\n",
      "iter 21100, loss: 0.099283\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- on, question answering, and summarization—all without task-onguaslatiormance-on many language model \n",
      "----\n",
      "iter 21200, loss: 0.098702\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 21300, loss: 0.098075\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 21400, loss: 0.097496\n",
      "----\n",
      "  reading comprehension, machine translation, questioy larization—all without task-schine the-aring comparation answering, and summarization—all without task-ode mraraph performs rudimentary reading co \n",
      "----\n",
      "iter 21500, loss: 0.096935\n",
      "----\n",
      " e’ve trained a large-scale unsuvent, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering \n",
      "----\n",
      "iter 21600, loss: 0.096328\n",
      "----\n",
      " achieves state-of-the-art performance onsmany language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 21700, loss: 0.095768\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine trarilh arizaerent paras \n",
      "----\n",
      "iter 21800, loss: 0.095225\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, anduperformance on many  \n",
      "----\n",
      "iter 21900, loss: 0.094635\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 22000, loss: 0.094093\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine tes coherent paragraphs of text, achieves state-of-the-art performance on many language model \n",
      "----\n",
      "iter 22100, loss: 0.093566\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates aod performance on many lang, arnsuperysiormtes coherent paragraphs of text, achieves state-of-the-art performance on many langua \n",
      "----\n",
      "iter 22200, loss: 0.092993\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answaring, and summariner the-art performance  \n",
      "----\n",
      "iter 22300, loss: 0.092467\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re unsummarization—all without task-pchine translation, question answering, and summarizati \n",
      "----\n",
      "iter 22400, loss: 0.091956\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 22500, loss: 0.091400\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and perding comprehension, machine translation, question answering, and summarization—all without task-ongu modeling -scale  \n",
      "----\n",
      "iter 22600, loss: 0.090889\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, question answering, and summarization—all without task-sceithout task-s comprehu \n",
      "----\n",
      "iter 22700, loss: 0.090394\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many lanchieves state-of-the-art perfon, question answering \n",
      "----\n",
      "iter 22800, loss: 0.089854\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 22900, loss: 0.089359\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation—all without task-l wiorms rthout task-s cion, question answering, and summarizati \n",
      "----\n",
      "iter 23000, loss: 0.088879\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, manchmarks, and performs \n",
      "----\n",
      "iter 23100, loss: 0.088355\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 23200, loss: 0.087876\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at tiner any language modeling benchmark-, and performs rudimentary reading comprtherin \n",
      "----\n",
      "iter 23300, loss: 0.087411\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 23400, loss: 0.086904\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 23500, loss: 0.086440\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- chideled agl and performs rudimentary reading comprehension, machine translation, question answerin \n",
      "----\n",
      "iter 23600, loss: 0.085990\n",
      "----\n",
      " e’ve trained a large-ed performs rudimentary reading comprehension, machine translation, question answering, and summariperformance on many languageachieves state-of-the-art performance on many langua \n",
      "----\n",
      "iter 23700, loss: 0.085498\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, andesummarization—all without task- \n",
      "----\n",
      "iter 23800, loss: 0.085049\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-scale unsual taruing, achieves state-of-the-art performance o \n",
      "----\n",
      "iter 23900, loss: 0.084614\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generat permsnd summarization—all without task-schich geneaanseamod large-scale unsupervised language model which generates coherent paragr \n",
      "----\n",
      "iter 24000, loss: 0.084137\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization, questioneansweri \n",
      "----\n",
      "iter 24100, loss: 0.083702\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- chine transleaschine translation, question answering, and summarization—all without task-schinh ann \n",
      "----\n",
      "iter 24200, loss: 0.083281\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 24300, loss: 0.082818\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 24400, loss: 0.082396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reanstanguage modeling benchmarks, and performs rudimentary reading cooprvised language mod ans restien comprehension, machine translation, question answering, and summarization—all without task-angu \n",
      "----\n",
      "iter 24500, loss: 0.081988\n",
      "----\n",
      " e’ve trained a large-scale unsuperant rarization—all without task-scale un re unmaragraphs orasertaperformance on many language modeling benchmarks, and performs rudimentary reading comprehension, mac \n",
      "----\n",
      "iter 24600, loss: 0.081538\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 24700, loss: 0.081129\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ongu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, quest \n",
      "----\n",
      "iter 24800, loss: 0.080733\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 24900, loss: 0.080296\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 25000, loss: 0.079900\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atrans coherent paragh performance on many language modeling benchmarks, and performs r \n",
      "----\n",
      "iter 25100, loss: 0.079515\n",
      "----\n",
      " e’ve trained a large-scale unsummarization—all without task-s comerent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading  \n",
      "----\n",
      "iter 25200, loss: 0.079090\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 25300, loss: 0.078705\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-adezation—all without task-scale unsupervised language model which generates coherent paragraphs of  \n",
      "----\n",
      "iter 25400, loss: 0.078332\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 25500, loss: 0.077918\n",
      "----\n",
      " achieves state-of-theoart performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 25600, loss: 0.077544\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinh ation, machine translation, question answering, and summarization—all without task-schine tra \n",
      "----\n",
      "iter 25700, loss: 0.077181\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 25800, loss: 0.076779\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 25900, loss: 0.076415\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s slation—all without task-scale unsupprehension, machine translation, question answering, and summa \n",
      "----\n",
      "iter 26000, loss: 0.076062\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model whins ation, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-onsuag  mode,isg  \n",
      "----\n",
      "iter 26100, loss: 0.075670\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs l question answering, and summarization—all without task-scale unsupervised language model which generates cohe \n",
      "----\n",
      "iter 26200, loss: 0.075316\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsumtage text, achieves state-of-the-art performance on many language modeling benchmarks, an \n",
      "----\n",
      "iter 26300, loss: 0.074972\n",
      "----\n",
      " e’arves coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering \n",
      "----\n",
      "iter 26400, loss: 0.074590\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 26500, loss: 0.074245\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinh any language modeling benchmarks, and performs rudimentary reading comprehension, machine tra \n",
      "----\n",
      "iter 26600, loss: 0.073910\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 26700, loss: 0.073537\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 26800, loss: 0.073201\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schite-the-art performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 26900, loss: 0.072875\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rchich gene \n",
      "----\n",
      "iter 27000, loss: 0.072511\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, qudised on, machine translation, question answering, an \n",
      "----\n",
      "iter 27100, loss: 0.072183\n",
      "----\n",
      "  riod langu mod mnnh marization—all without task-schine text, at tarks, and performs rudimentary reading comprehension, machine translation- ru sion, machine translation, question answering, and summa \n",
      "----\n",
      "iter 27200, loss: 0.071865\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves st tr-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 27300, loss: 0.071510\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 27400, loss: 0.071190\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuparestion answering, and summarization—all without task-schine text, atring benchmarks, an \n",
      "----\n",
      "iter 27500, loss: 0.070880\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 27600, loss: 0.070533\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 27700, loss: 0.070222\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un rained w large-scale unsupervised language model which generates coherent paragraphs of tex \n",
      "----\n",
      "iter 27800, loss: 0.069919\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling monchieves strtined a large-scale un \n",
      "----\n",
      "iter 27900, loss: 0.069580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answergnganswering, and summarization—all with \n",
      "----\n",
      "iter 28000, loss: 0.069277\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- swithodt task-scale unsupervised language model which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 28100, loss: 0.068982\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 28200, loss: 0.068651\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 28300, loss: 0.068356\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale ungu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 28400, loss: 0.068069\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 28500, loss: 0.067746\n",
      "----\n",
      " achieves state-of-the-art performance on mary language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 28600, loss: 0.067458\n",
      "----\n",
      "  reading comprehension, machine translation, quessitate-t performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and \n",
      "----\n",
      "iter 28700, loss: 0.067178\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves rinea t aud aensane- wangeves ation, machine translation, question answering, and summariza \n",
      "----\n",
      "iter 28800, loss: 0.066863\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, age-sca e anslaaru unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art perfor \n",
      "----\n",
      "iter 28900, loss: 0.066582\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-incompathener izedit largragraphs of text, achieves state-of- \n",
      "----\n",
      "iter 29000, loss: 0.066310\n",
      "----\n",
      " e’ve trained a large-scale unsion, machine translation, question answering, and summarization—all without task-schine textcomprehension, machine translation, question answering, and summarization—all  \n",
      "----\n",
      "iter 29100, loss: 0.066003\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summnge the-art performance on  \n",
      "----\n",
      "iter 29200, loss: 0.065729\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re unsummarization—all without task-ode-ert paragraphs of text, achieves state-of-the-art p \n",
      "----\n",
      "iter 29300, loss: 0.065464\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 29400, loss: 0.065164\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 29500, loss: 0.064898\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un resumparanch nchmarks, question answering, and summarization—all without task-scale un rain \n",
      "----\n",
      "iter 29600, loss: 0.064639\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 29700, loss: 0.064346\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and porformance on many l ceion—all without task-schitheat ta tnge ension, que-scale unsupervised language model which gener \n",
      "----\n",
      "iter 29800, loss: 0.064087\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without tascaod redimentary reading comprehension, machine tod lrwhine translation, question answering, and summa \n",
      "----\n",
      "iter 29900, loss: 0.063835\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language madel wand mgensaansymarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task \n",
      "----\n",
      "iter 30000, loss: 0.063549\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 30100, loss: 0.063296\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the \n",
      "----\n",
      "iter 30200, loss: 0.063050\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 30300, loss: 0.062771\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 30400, loss: 0.062524\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-pchine translation, question answering, and summarization—all without task-scale many language model \n",
      "----\n",
      "iter 30500, loss: 0.062285\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 30600, loss: 0.062012\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 30700, loss: 0.061771\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and perf \n",
      "----\n",
      "iter 30800, loss: 0.061537\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performand summarization—all without task-sc, achieves state-of-the-art pe \n",
      "----\n",
      "iter 30900, loss: 0.061270\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 31000, loss: 0.061035\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale priuel swering, and summarization—all without task-orization—all without task-scale un ue mspu \n",
      "----\n",
      "iter 31100, loss: 0.060807\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 31200, loss: 0.060546\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 31300, loss: 0.060316\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and su-art performance on ms ruined a lalg moneling benchmarks, and performs rudimentary reading comprehension, machine translation, qu \n",
      "----\n",
      "iter 31400, loss: 0.060093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language modes wand gragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehensio \n",
      "----\n",
      "iter 31500, loss: 0.059838\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 31600, loss: 0.059614\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinchierent paragraphs of text, achieves stves states coherent panchmare uherehension, machine tra \n",
      "----\n",
      "iter 31700, loss: 0.059396\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many trt performance on many language modeling benchmarks,  \n",
      "----\n",
      "iter 31800, loss: 0.059146\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 31900, loss: 0.058927\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupprehperformance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 32000, loss: 0.058714\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language modk-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling ben \n",
      "----\n",
      "iter 32100, loss: 0.058469\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 32200, loss: 0.058255\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—allewithout task-ongu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, quest \n",
      "----\n",
      "iter 32300, loss: 0.058046\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling b nchmarks, and performs rudimentary \n",
      "----\n",
      "iter 32400, loss: 0.057807\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and sud reiterms rudimentary readin \n",
      "----\n",
      "iter 32500, loss: 0.057598\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupard performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 32600, loss: 0.057394\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 32700, loss: 0.057159\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudiony lanhige translation, question answering, and summarization—all without task-scale unsupervisediog, and  \n",
      "----\n",
      "iter 32800, loss: 0.056955\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-scale un restion answering, and summarization—all without tas \n",
      "----\n",
      "iter 32900, loss: 0.056755\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on mancviper t performs rudimentary reading comprehension, mac \n",
      "----\n",
      "iter 33000, loss: 0.056525\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 33100, loss: 0.056325\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmaraling comprehension, machine translation, question answering, and summarization—all wi \n",
      "----\n",
      "iter 33200, loss: 0.056130\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 33300, loss: 0.055905\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and pertion answering, and summarization—all without task-oks,pand performs rudimentary reading comprehension, machine trans \n",
      "----\n",
      "iter 33400, loss: 0.055708\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-angu marization—all with-ud a le unsupervised language model which generates coherent paragraphs of  \n",
      "----\n",
      "iter 33500, loss: 0.055517\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmary readenu mod leage-scale un \n",
      "----\n",
      "iter 33600, loss: 0.055297\n",
      "----\n",
      " achieves state-of-the-art performance on ot reading comprehension, machine translation, question answering, and summarization—all without task-scale unsummaraling comparading comprehension, machine tr \n",
      "----\n",
      "iter 33700, loss: 0.055104\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, moreagraphs of text, achieves state-of-the-art performance on many language modeling be \n",
      "----\n",
      "iter 33800, loss: 0.054917\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 33900, loss: 0.054701\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 34000, loss: 0.054513\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ongu modeling benchmarks, and lerformance on many language modeling benchmarks, and performs rudimen \n",
      "----\n",
      "iter 34100, loss: 0.054330\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 34200, loss: 0.054118\n",
      "----\n",
      " achieves state-of-the-art performance on many languagegmodeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 34300, loss: 0.053933\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question an \n",
      "----\n",
      "iter 34400, loss: 0.053754\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and perfor, pachon large \n",
      "----\n",
      "iter 34500, loss: 0.053546\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling monglawiorforaring, and summarization—all without task-oks, and performs rudimentary reading comprehension, machine translation, questio \n",
      "----\n",
      "iter 34600, loss: 0.053365\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s coherege manchmarks, and performs rudimenerasorudimentary readesummatasmadel statecel which genera \n",
      "----\n",
      "iter 34700, loss: 0.053189\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performindec, aresti \n",
      "----\n",
      "iter 34800, loss: 0.052985\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehensrained a large-scale unsupervised language model which generates coherent paragra \n",
      "----\n",
      "iter 34900, loss: 0.052808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsu marization—all without task-sceithout task-scale un restimancomarestion answering, and su \n",
      "----\n",
      "iter 35000, loss: 0.052636\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 35100, loss: 0.052436\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 35200, loss: 0.052262\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un performs rudimentary reading comprehension, machine translation, question answering, and su \n",
      "----\n",
      "iter 35300, loss: 0.052093\n",
      "----\n",
      " e’ve trained a large-siny and serformance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without t \n",
      "----\n",
      "iter 35400, loss: 0.051897\n",
      "----\n",
      " achieves state-of-the-art performance on many langtage mod large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language m \n",
      "----\n",
      "iter 35500, loss: 0.051727\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—allewithout task-scale un uragraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 35600, loss: 0.051561\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 35700, loss: 0.051368\n",
      "----\n",
      " any language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuagog, achieves state-of-the-art  \n",
      "----\n",
      "iter 35800, loss: 0.051202\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarizationt parszation—all without task-scale unsupervised language model which generates coherent paragraphs of text, achieves  \n",
      "----\n",
      "iter 35900, loss: 0.051039\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 36000, loss: 0.050850\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 36100, loss: 0.050687\n",
      "----\n",
      "  reading comprehension, machine translation, question answering,land summarization—all without task-scale unsupmarizationt parization—all without task-schins and summarization—all without task-scale u \n",
      "----\n",
      "iter 36200, loss: 0.050527\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance od mnine, achieves state-of-the-art performance on many langua \n",
      "----\n",
      "iter 36300, loss: 0.050341\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 36400, loss: 0.050181\n",
      "----\n",
      "  reading comprehension, machine translation, question answersiormand summarization—all without task-ochine text, achieves state-of-the-art performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 36500, loss: 0.050025\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language mode-ing benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 36600, loss: 0.049842\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 36700, loss: 0.049685\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the \n",
      "----\n",
      "iter 36800, loss: 0.049532\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 36900, loss: 0.049352\n",
      "----\n",
      " achieves stata-of-the-art performance on many language modeling banguage modeling benchmarks, and perfhs of text, achieves state-of-the-art performance on many language modeling benchmprestion answeri \n",
      "----\n",
      "iter 37000, loss: 0.049198\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the \n",
      "----\n",
      "iter 37100, loss: 0.049048\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 37200, loss: 0.048872\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 37300, loss: 0.048721\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schite-the-art performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 37400, loss: 0.048573\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves statentere  sranchmares, and performs rudimentary reading comprehension, machine translatio \n",
      "----\n",
      "iter 37500, loss: 0.048400\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, anguage model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling b \n",
      "----\n",
      "iter 37600, loss: 0.048251\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuperent paragraphs of text, achieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 37700, loss: 0.048106\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 37800, loss: 0.047936\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 37900, loss: 0.047790\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsummarization—all without task-scasdchmarks, and performs rudimentary reading comprehension, \n",
      "----\n",
      "iter 38000, loss: 0.047648\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 38100, loss: 0.047481\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 38200, loss: 0.047338\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- chine translation, question answering, and summarization—all without task-scale unsuparks, and perf \n",
      "----\n",
      "iter 38300, loss: 0.047198\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 38400, loss: 0.047034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 38500, loss: 0.046893\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsumanes staterande onpue mangecoms ef tancasks sod loweion—all without task-pnnzatiorms rudi \n",
      "----\n",
      "iter 38600, loss: 0.046756\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 38700, loss: 0.046594\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 38800, loss: 0.046457\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re unsummaraling comprehension, machine translation, question answering, and summarization— \n",
      "----\n",
      "iter 38900, loss: 0.046321\n",
      "----\n",
      " e’ve trained a large-scale unsupervsiorms rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- dezed oge mangu aod rudimentardised language m \n",
      "----\n",
      "iter 39000, loss: 0.046163\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 39100, loss: 0.046027\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schite-the-art performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 39200, loss: 0.045895\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 39300, loss: 0.045738\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 39400, loss: 0.045606\n",
      "----\n",
      "  reading comprehension, machine translation, question answerench generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimen \n",
      "----\n",
      "iter 39500, loss: 0.045475\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 39600, loss: 0.045322\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 39700, loss: 0.045191\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re unmaragragr phs of text, achieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 39800, loss: 0.045063\n",
      "----\n",
      " e’ve trained a larao- cazat ogt prestion answering, and summarization—all without task-schite-trering, and summarization—all without task-scale unsupparization—all without task-scale un restion answer \n",
      "----\n",
      "iter 39900, loss: 0.044912\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 40000, loss: 0.044784\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuppvesestange marization—all without task-scale un many language modeling benchmarks, and p \n",
      "----\n",
      "iter 40100, loss: 0.044658\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 40200, loss: 0.044509\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 40300, loss: 0.044383\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupank-sinaripe onerehension, machine translation, question answering, and summarization—all \n",
      "----\n",
      "iter 40400, loss: 0.044259\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model swourge onslation, question answering, and summarization—all without task-schine text, atrained a large-scale unsupervised language model which g \n",
      "----\n",
      "iter 40500, loss: 0.044113\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehering, and summarization—all without task-scale unsupparization—all without task-sch \n",
      "----\n",
      "iter 40600, loss: 0.043989\n",
      "----\n",
      "  reading comprehension, machine translation, question answerinc, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine tra \n",
      "----\n",
      "iter 40700, loss: 0.043867\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 40800, loss: 0.043723\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 40900, loss: 0.043602\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich gederanslation, question answering, and summarization—all without task-anguachieves state-of- \n",
      "----\n",
      "iter 41000, loss: 0.043482\n",
      "----\n",
      " e’ve trained a large-, age msnd summarization—all without task- ch aineary rerformance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, questi \n",
      "----\n",
      "iter 41100, loss: 0.043340\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 41200, loss: 0.043221\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmanguagu mod lergraphs of text, achieves state-of-the-art performance on many language mo \n",
      "----\n",
      "iter 41300, loss: 0.043103\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 41400, loss: 0.042963\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 41500, loss: 0.042846\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsummarization—all without task-scale unsupprehension, machine translation, question coherent \n",
      "----\n",
      "iter 41600, loss: 0.042730\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves statenterealing benchmarks, and performs rudimentary reading comprehension, machine transla \n",
      "----\n",
      "iter 41700, loss: 0.042593\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rksite tr task-scale un rained a large-scale unsupervised languagitapragu mod lasiormancecomprehension, machine \n",
      "----\n",
      "iter 41800, loss: 0.042477\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuperestion answering, and summarization—all without task-scale unsupmarization—all without  \n",
      "----\n",
      "iter 41900, loss: 0.042363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 42000, loss: 0.042228\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 42100, loss: 0.042114\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuagalaod rent paragraphs of text, achieves state-of-the-art performance on many language mo \n",
      "----\n",
      "iter 42200, loss: 0.042002\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 42300, loss: 0.041869\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 42400, loss: 0.041757\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schine text, athieves s re uionearhineratesec whins tanragrap \n",
      "----\n",
      "iter 42500, loss: 0.041647\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 42600, loss: 0.041516\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 42700, loss: 0.041406\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re unsupervised language model which generates coherent paragraphs of text, achieves staten \n",
      "----\n",
      "iter 42800, loss: 0.041297\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieres lard uudimayel which generates coherent paragraphs of text, achieves state-of-the-art perfo \n",
      "----\n",
      "iter 42900, loss: 0.041168\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all withoud task- \n",
      "----\n",
      "iter 43000, loss: 0.041060\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onsuaras pes-starenge tisecoherent paragraphs of text, achieves state-of-the-art performance on many \n",
      "----\n",
      "iter 43100, loss: 0.040953\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 43200, loss: 0.040826\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 43300, loss: 0.040719\n",
      "----\n",
      "  reading comprehension, machine translation, quessitiof tentcomprehension, machine translation, question answering, and summarization—all without task-angu modeling benguage modeling benchmarks, and p \n",
      "----\n",
      "iter 43400, loss: 0.040614\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 43500, loss: 0.040489\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine traring, an— ll anyagragragraphs of text, achieves state-of-the-art  \n",
      "----\n",
      "iter 43600, loss: 0.040384\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art p \n",
      "----\n",
      "iter 43700, loss: 0.040280\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 43800, loss: 0.040156\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 43900, loss: 0.040053\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s coherewling benchmarks, and performs rudimentary reading comprehension, machine translation, quest \n",
      "----\n",
      "iter 44000, loss: 0.039951\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 44100, loss: 0.039829\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 44200, loss: 0.039727\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s comprehension, machine translation, question answering, and summarization—all without task-ons ati \n",
      "----\n",
      "iter 44300, loss: 0.039627\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling bmnchmarks, and performs rudimentary \n",
      "----\n",
      "iter 44400, loss: 0.039507\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 44500, loss: 0.039407\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-anguwhine text, atlang benchmarks, and performs rudimentary reading comprehension, machine translati \n",
      "----\n",
      "iter 44600, loss: 0.039307\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 44700, loss: 0.039189\n",
      "----\n",
      " achievestindestion answering, and summarization—all without task-scale un reading comprehension, machine trans perviged language model which generates coherent paragraphs of text, achieves state-of-th \n",
      "----\n",
      "iter 44800, loss: 0.039090\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmaraling comprehension, machine translation, question answering, and summarization—all wi \n",
      "----\n",
      "iter 44900, loss: 0.038993\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 45000, loss: 0.038876\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 45100, loss: 0.038779\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, question answering, and summarization—all without task-scale unsummachige taansl \n",
      "----\n",
      "iter 45200, loss: 0.038683\n",
      "----\n",
      " e’ve trained a large-snd swa-s of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answer \n",
      "----\n",
      "iter 45300, loss: 0.038568\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 45400, loss: 0.038472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schension, machine translation, question answering, and summa \n",
      "----\n",
      "iter 45500, loss: 0.038377\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 45600, loss: 0.038264\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 45700, loss: 0.038170\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, oncand performance on many language modeling benchmarks, and performs rudimentar \n",
      "----\n",
      "iter 45800, loss: 0.038077\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 45900, loss: 0.037965\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 46000, loss: 0.037872\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atrand s mtata-of-the-art performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 46100, loss: 0.037780\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 46200, loss: 0.037670\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine traring, and su monehala modeling benchmarks, and performs rudimenta \n",
      "----\n",
      "iter 46300, loss: 0.037579\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all withoy re performs rudimentary reading comprehension, machine translation, question answering, and summarization— \n",
      "----\n",
      "iter 46400, loss: 0.037488\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 46500, loss: 0.037380\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 46600, loss: 0.037290\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achieves statary reading comprehension, machine translation, question answering, and su \n",
      "----\n",
      "iter 46700, loss: 0.037201\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 46800, loss: 0.037094\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 46900, loss: 0.037005\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schitezarge-scale unsion, machine translation, question answeutntarkstion answering, and summarizati \n",
      "----\n",
      "iter 47000, loss: 0.036917\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 47100, loss: 0.036812\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 47200, loss: 0.036724\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmangmany language modeling benchmarks, and performs rudimentary reading comprehension, ma \n",
      "----\n",
      "iter 47300, loss: 0.036638\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 47400, loss: 0.036534\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 47500, loss: 0.036448\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupare , and performs rudimentary reading comprehension, machine translation, question answe \n",
      "----\n",
      "iter 47600, loss: 0.036362\n",
      "----\n",
      " e’ve trained a large-scale unsupervised langungu ge translation, question answering, and summarization—all without task-sching achieves state-of-the-art performance on many language modeling benchmark \n",
      "----\n",
      "iter 47700, loss: 0.036260\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 47800, loss: 0.036175\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s coonm hension, machine translation, question answering, and summarization—all without task-scale u \n",
      "----\n",
      "iter 47900, loss: 0.036091\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 48000, loss: 0.035990\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 48100, loss: 0.035906\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scasedimerent parization—all without task-scale un reanitatep t tary readerunsuppre zarion, question \n",
      "----\n",
      "iter 48200, loss: 0.035823\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 48300, loss: 0.035724\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, lachine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 48400, loss: 0.035641\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schine translation, question answering, and summarization—all \n",
      "----\n",
      "iter 48500, loss: 0.035560\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 48600, loss: 0.035461\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension—ms manswering, and summarization—all without task-pchine translation, questio \n",
      "----\n",
      "iter 48700, loss: 0.035380\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uerms rudimentary reading comprehension, machine translation, question answering, and summa \n",
      "----\n",
      "iter 48800, loss: 0.035299\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 48900, loss: 0.035202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 49000, loss: 0.035123\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s comprehension, machine translation, question answering, and summarization—all without task-scale u \n",
      "----\n",
      "iter 49100, loss: 0.035043\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 49200, loss: 0.034947\n",
      "----\n",
      " achieves state-of-the-art perfor ance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 49300, loss: 0.034869\n",
      "----\n",
      "  reading compaechmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupeach generanslaay langupanguage textasksd \n",
      "----\n",
      "iter 49400, loss: 0.034790\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 49500, loss: 0.034695\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading modeling benchmarks, and performs rudimentary reading comprehension, machine translation, q \n",
      "----\n",
      "iter 49600, loss: 0.034618\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuppreization—all without task- dehiodel which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 49700, loss: 0.034540\n",
      "----\n",
      " e’vrat of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—a \n",
      "----\n",
      "iter 49800, loss: 0.034447\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 49900, loss: 0.034371\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at teves state-of-the-art performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 50000, loss: 0.034294\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 50100, loss: 0.034202\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 50200, loss: 0.034127\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un perfmparagraphs of text, achieves state-of-the-art performance on many language modeling be \n",
      "----\n",
      "iter 50300, loss: 0.034051\n",
      "----\n",
      " e’ve trained a large-scala u puriugmaneuperent pu benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-ongu modeling  \n",
      "----\n",
      "iter 50400, loss: 0.033961\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 50500, loss: 0.033886\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale ension, machine translation, question answering, and summarization—all without task-schite-ond \n",
      "----\n",
      "iter 50600, loss: 0.033812\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmardised s rudimentary reading  \n",
      "----\n",
      "iter 50700, loss: 0.033722\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 50800, loss: 0.033649\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un u puteans any language modeling benchmarks, and performs rudimentary reading comprehension, \n",
      "----\n",
      "iter 50900, loss: 0.033575\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 51000, loss: 0.033487\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 51100, loss: 0.033415\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atntask-sor text, ationce on many language modeling benchmarks, and performs rudimentar \n",
      "----\n",
      "iter 51200, loss: 0.033342\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 51300, loss: 0.033255\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 51400, loss: 0.033183\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un unsupervised language model which generates coherent paragraphs of text, achieves state-of- \n",
      "----\n",
      "iter 51500, loss: 0.033112\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 51600, loss: 0.033025\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 51700, loss: 0.032955\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-s hinheder nge-scale unsupervised language model which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 51800, loss: 0.032884\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 51900, loss: 0.032799\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 52000, loss: 0.032730\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schiteling benchmarks, and performs rudimentary reading comprehension, machine translation, questien \n",
      "----\n",
      "iter 52100, loss: 0.032660\n",
      "----\n",
      " e’ve trained g reizarion, question answering, and summarization—all without task-schich gederanslation, question answering, and summarization—all without task-schinh ation, machine translation, questi \n",
      "----\n",
      "iter 52200, loss: 0.032576\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 52300, loss: 0.032507\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupart performance on many language modeling benchmarks, and performs rudimentary reading co \n",
      "----\n",
      "iter 52400, loss: 0.032439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 52500, loss: 0.032355\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 52600, loss: 0.032288\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode mraragh performs rudimentary reading comprehension, machine translation, question answering, and \n",
      "----\n",
      "iter 52700, loss: 0.032220\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 52800, loss: 0.032138\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all withoat task- \n",
      "----\n",
      "iter 52900, loss: 0.032071\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupank-, ares, and performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 53000, loss: 0.032004\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 53100, loss: 0.031923\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 53200, loss: 0.031857\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atrand s mmaragraphipent pdestion answering, and summarization—all without task-ichegen \n",
      "----\n",
      "iter 53300, loss: 0.031791\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 53400, loss: 0.031711\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 53500, loss: 0.031646\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinh anneagraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 53600, loss: 0.031581\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 53700, loss: 0.031501\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 53800, loss: 0.031437\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsutart performs rudimentary reading comprehension, machine translation, question answering,  \n",
      "----\n",
      "iter 53900, loss: 0.031373\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 54000, loss: 0.031294\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 54100, loss: 0.031231\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uerun-y modeling benchmarks, and performs rudimentary reading comprehension, machine transl \n",
      "----\n",
      "iter 54200, loss: 0.031167\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 54300, loss: 0.031090\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 54400, loss: 0.031028\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine trat out tank-phe erates coherent parag bension, machine translation, question answering, and \n",
      "----\n",
      "iter 54500, loss: 0.030965\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 54600, loss: 0.030888\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 54700, loss: 0.030827\n",
      "----\n",
      "  reading comprehension, machine orates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 54800, loss: 0.030764\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 54900, loss: 0.030689\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 55000, loss: 0.030628\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schithlarge-scale unsupervised language model which generates coherent paragraphs of text, achieves  \n",
      "----\n",
      "iter 55100, loss: 0.030567\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, ane , hich generates coh \n",
      "----\n",
      "iter 55200, loss: 0.030492\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 55300, loss: 0.030432\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- on, question answering, and summarization—all without task-scale unsupmang, and performs rudimentar \n",
      "----\n",
      "iter 55400, loss: 0.030371\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 55500, loss: 0.030297\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 55600, loss: 0.030238\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many language modeling benchmarks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 55700, loss: 0.030178\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 55800, loss: 0.030105\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 55900, loss: 0.030047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un unsupervised language model which generates coherent paragraphs of text, achieves state-of- \n",
      "----\n",
      "iter 56000, loss: 0.029987\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 56100, loss: 0.029915\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 56200, loss: 0.029857\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ansuage chmarks, and performs rudimentary reading comprehension, machine translation, question answe \n",
      "----\n",
      "iter 56300, loss: 0.029799\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 56400, loss: 0.029727\n",
      "----\n",
      " achieves state-of-the-art rariormance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 56500, loss: 0.029670\n",
      "----\n",
      "  reading comprehension, machine the-are performs rudimanent peragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehensi \n",
      "----\n",
      "iter 56600, loss: 0.029612\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 56700, loss: 0.029542\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 56800, loss: 0.029486\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achieves state-of-the-art performs rudimentary reading comprehension, machine translati \n",
      "----\n",
      "iter 56900, loss: 0.029428\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves squesthervization—all without task-scale un uragraphs tadks, and performs rudimentary readi \n",
      "----\n",
      "iter 57000, loss: 0.029359\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 57100, loss: 0.029303\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atring benchmarks, and performs rudimentary re for text, achieves state-of-the-art perf \n",
      "----\n",
      "iter 57200, loss: 0.029246\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 57300, loss: 0.029177\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 57400, loss: 0.029122\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-arization—all without task-sks sodua which generates coherent paragraphs of text, achieves state-of- \n",
      "----\n",
      "iter 57500, loss: 0.029067\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 57600, loss: 0.028998\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 57700, loss: 0.028944\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schensiany language modeling benchmarks, and performs rudimentary reading comprehension, machine tra \n",
      "----\n",
      "iter 57800, loss: 0.028889\n",
      "----\n",
      " e’ve trained a large-scalhined a leagraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reansranslation, machine translation, question  \n",
      "----\n",
      "iter 57900, loss: 0.028821\n",
      "----\n",
      " achieves state-of-the-art perforla ledinering benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarizat \n",
      "----\n",
      "iter 58000, loss: 0.028768\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many language modeling benchmprestion answering, and summarization—all without task-schich  \n",
      "----\n",
      "iter 58100, loss: 0.028713\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 58200, loss: 0.028646\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 58300, loss: 0.028593\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uragraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 58400, loss: 0.028539\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 58500, loss: 0.028473\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 58600, loss: 0.028421\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuperent paragraphs of text, achieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 58700, loss: 0.028367\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 58800, loss: 0.028302\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 58900, loss: 0.028250\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinh ance pnensined a large-scale unsupervised language model which generates coherent paragraphs  \n",
      "----\n",
      "iter 59000, loss: 0.028198\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 59100, loss: 0.028133\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 59200, loss: 0.028082\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-inslation—all without task-scale unsuparkstion answering, and summarization—all without task-schine  \n",
      "----\n",
      "iter 59300, loss: 0.028030\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragnbension, machine translation, question answering, and summarization—all without task-s rithout task-scale ungu mod \n",
      "----\n",
      "iter 59400, loss: 0.027966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 59500, loss: 0.027915\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trangu ane  sane manc language modeling benchmarks, and performs rudimentary reading comprehensi \n",
      "----\n",
      "iter 59600, loss: 0.027864\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 59700, loss: 0.027800\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, muditarms rudimentary reading comprehension, machine translation, question a \n",
      "----\n",
      "iter 59800, loss: 0.027751\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onslation—all without task-sceathout t pes ttate-of-the-art performance on many language modeling be \n",
      "----\n",
      "iter 59900, loss: 0.027700\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 60000, loss: 0.027637\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 60100, loss: 0.027588\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atring benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 60200, loss: 0.027537\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 60300, loss: 0.027475\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 60400, loss: 0.027426\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schins and summarization—all without task-schine traritalms rudimentary reading comprehension, machi \n",
      "----\n",
      "iter 60500, loss: 0.027377\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 60600, loss: 0.027315\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 60700, loss: 0.027267\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at text, atding comprehension, machine the-e task-scale un uragraphs sf text, achieves  \n",
      "----\n",
      "iter 60800, loss: 0.027218\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 60900, loss: 0.027157\n",
      "----\n",
      " achieves state-of-the-art performance oneraige-scale unsion, machine translation, question answering, and summarization—all without task-schine text, atring benchmarks, and performs rudimentary readin \n",
      "----\n",
      "iter 61000, loss: 0.027110\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onsianl ma hine translation, question answering, and summarization—all without task-ode trate-of-the \n",
      "----\n",
      "iter 61100, loss: 0.027061\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 61200, loss: 0.027001\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 61300, loss: 0.026954\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuparestion answering, and summarization—all without task-s comprehension, machine translati \n",
      "----\n",
      "iter 61400, loss: 0.026905\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 61500, loss: 0.026846\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without tasks \n",
      "----\n",
      "iter 61600, loss: 0.026799\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at text, achieves statermaac-s coherent parization—all without task-scale unsupanguage  \n",
      "----\n",
      "iter 61700, loss: 0.026752\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 61800, loss: 0.026693\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 61900, loss: 0.026647\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un u putask- she-answering, and summarization—all without task-scale unsupanks, and performs r \n",
      "----\n",
      "iter 62000, loss: 0.026600\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 62100, loss: 0.026542\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 62200, loss: 0.026496\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-ochine text, atraige-scale unsion, machine translation, quest \n",
      "----\n",
      "iter 62300, loss: 0.026449\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 62400, loss: 0.026392\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling banchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 62500, loss: 0.026347\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuperent paragraphs of text, achieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 62600, loss: 0.026301\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 62700, loss: 0.026244\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 62800, loss: 0.026199\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uel, machine translation, question answering, and summarization—all without task-schine tex \n",
      "----\n",
      "iter 62900, loss: 0.026154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 63000, loss: 0.026097\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 63100, loss: 0.026053\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un rhinec teves starentaaks, and performs rudimentary reading comprehension, machine translati \n",
      "----\n",
      "iter 63200, loss: 0.026008\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 63300, loss: 0.025952\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comares state-of-the-art performance on many language modeling benchmarks, and performs rud \n",
      "----\n",
      "iter 63400, loss: 0.025909\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uriud many language modeling benchmarks, and performs rudimentary reading comprehension, ma \n",
      "----\n",
      "iter 63500, loss: 0.025864\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 63600, loss: 0.025809\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, adestion answering, and summarization—all without task-scale un reinea s rudimentary reading comprehension, machine translat \n",
      "----\n",
      "iter 63700, loss: 0.025766\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trate-of-the-art performance on many language modeling benchmarks, and performs rudimentary read \n",
      "----\n",
      "iter 63800, loss: 0.025721\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance pn mance on many language modeling benchmarks, and performs ru \n",
      "----\n",
      "iter 63900, loss: 0.025667\n",
      "----\n",
      " achieves state-of-the-art performance on many lrnguatndes comparagraphs trans of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comp \n",
      "----\n",
      "iter 64000, loss: 0.025624\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-sching achieves state-of-the-art performance on many language modeling benchmarks, and performs rudi \n",
      "----\n",
      "iter 64100, loss: 0.025580\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 64200, loss: 0.025526\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 64300, loss: 0.025484\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onslation—all without task-odesed language model which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 64400, loss: 0.025441\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 64500, loss: 0.025387\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 64600, loss: 0.025345\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schiteling benchmarks, and performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 64700, loss: 0.025303\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 64800, loss: 0.025249\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 64900, loss: 0.025208\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsuppokp, hnd performs rudimentary reading comprehension, machine translation, question answe \n",
      "----\n",
      "iter 65000, loss: 0.025166\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 65100, loss: 0.025113\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmmanguage mon many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answ \n",
      "----\n",
      "iter 65200, loss: 0.025073\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupancashuaehension, machine translation, question answering, and summarization—all without  \n",
      "----\n",
      "iter 65300, loss: 0.025031\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 65400, loss: 0.024979\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 65500, loss: 0.024938\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at, mscala unsupervised language model which generates coherent paragraphs of text, ach \n",
      "----\n",
      "iter 65600, loss: 0.024897\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 65700, loss: 0.024845\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 65800, loss: 0.024805\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich gtatask-scale unsupmarization—all without task-scale unsupmarization—all without task-scale u \n",
      "----\n",
      "iter 65900, loss: 0.024764\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 66000, loss: 0.024713\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 66100, loss: 0.024674\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at text, achieves wt ta tns coherent paragraphs of text, achieves state-of-the-art perf \n",
      "----\n",
      "iter 66200, loss: 0.024633\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 66300, loss: 0.024582\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, q \n",
      "----\n",
      "iter 66400, loss: 0.024544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinrmang benchmarks, and performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 66500, loss: 0.024503\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 66600, loss: 0.024453\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 66700, loss: 0.024415\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, question answering, and summarization—all without task-schine text, agu marizati \n",
      "----\n",
      "iter 66800, loss: 0.024375\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 66900, loss: 0.024325\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 67000, loss: 0.024287\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieves strained a large-scale unsupervised language model which generates coherent pa \n",
      "----\n",
      "iter 67100, loss: 0.024248\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generatext, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, mac \n",
      "----\n",
      "iter 67200, loss: 0.024198\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 67300, loss: 0.024161\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupprehension, machine translation, question answering, and summarization—all without task-s \n",
      "----\n",
      "iter 67400, loss: 0.024122\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on ms rusimentaresliencans rrineu snd ard pedion—all machine t \n",
      "----\n",
      "iter 67500, loss: 0.024073\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 67600, loss: 0.024035\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schideled l pe -euteading comprehension, machine translation, question answering, and summarization— \n",
      "----\n",
      "iter 67700, loss: 0.023997\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 67800, loss: 0.023948\n",
      "----\n",
      " achieves state-t -orms redimentaahe ta achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answeri \n",
      "----\n",
      "iter 67900, loss: 0.023912\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine thateoofmtext, athi performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 68000, loss: 0.023873\n",
      "----\n",
      " e’ve trained a large-scale unsupervised sare performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupancascale unsupervised l \n",
      "----\n",
      "iter 68100, loss: 0.023825\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 68200, loss: 0.023789\n",
      "----\n",
      "  reading comprehering, and summarization—all without task-schine text, agn machine translation, question answering, and summarization—all without task-scale unsupancascale unsupervised language model  \n",
      "----\n",
      "iter 68300, loss: 0.023751\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 68400, loss: 0.023704\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 68500, loss: 0.023667\n",
      "----\n",
      "  readiog answerine, and summarization—all without task-scale unsupmarization—all without task-scale unsupmarization—all without task- sndestion ans ension, machine translation, question answering, and \n",
      "----\n",
      "iter 68600, loss: 0.023630\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 68700, loss: 0.023583\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 68800, loss: 0.023547\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinchmarks, and performs rudimentary reading comprehension, machine translation, question answerin \n",
      "----\n",
      "iter 68900, loss: 0.023510\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 69000, loss: 0.023463\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 69100, loss: 0.023428\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atring benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 69200, loss: 0.023391\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 69300, loss: 0.023345\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 69400, loss: 0.023310\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un re utask- sork- gence translation, question answering, and summarization—all without task-  \n",
      "----\n",
      "iter 69500, loss: 0.023274\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 69600, loss: 0.023228\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 69700, loss: 0.023193\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many language modeling benchmarks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 69800, loss: 0.023157\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 69900, loss: 0.023112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 70000, loss: 0.023077\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich gt task-s comprehension, machine translation, question answering, and summarization—all witho \n",
      "----\n",
      "iter 70100, loss: 0.023042\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 70200, loss: 0.022997\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 70300, loss: 0.022963\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all with-en, mansimentary reading comprehension, machine translation, question answering, and summarization—all witho \n",
      "----\n",
      "iter 70400, loss: 0.022927\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 70500, loss: 0.022883\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 70600, loss: 0.022849\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmangisen anca whics and summarization—all without task-scale un u gr wite-on—all wite-tho \n",
      "----\n",
      "iter 70700, loss: 0.022814\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 70800, loss: 0.022770\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 70900, loss: 0.022737\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- he ef taned aedelaswiudimentary reading comprehension, machine translation, question answering, and \n",
      "----\n",
      "iter 71000, loss: 0.022702\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 71100, loss: 0.022658\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 71200, loss: 0.022625\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schidertaatephp,eanswering, and summarization—all without task-scale unsupmarization—all without tas \n",
      "----\n",
      "iter 71300, loss: 0.022591\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 71400, loss: 0.022547\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 71500, loss: 0.022515\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, aching benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 71600, loss: 0.022481\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 71700, loss: 0.022438\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 71800, loss: 0.022405\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schithmany language modeling benchmarks, and performs rudimentary reading comprehension, machine tra \n",
      "----\n",
      "iter 71900, loss: 0.022372\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 72000, loss: 0.022329\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 72100, loss: 0.022297\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode crateperformance on many language modeling benchmarks, and performs rudimentary reading comprehe \n",
      "----\n",
      "iter 72200, loss: 0.022264\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 72300, loss: 0.022221\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 72400, loss: 0.022190\n",
      "----\n",
      "  reading comprehening, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summariz \n",
      "----\n",
      "iter 72500, loss: 0.022157\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 72600, loss: 0.022115\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 72700, loss: 0.022083\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieg comprehension, machine translation, question answering, and summarization—all wi \n",
      "----\n",
      "iter 72800, loss: 0.022050\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 72900, loss: 0.022009\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 73000, loss: 0.021978\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schinn—all without task-onsiany language modeling benchmarks, \n",
      "----\n",
      "iter 73100, loss: 0.021945\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 73200, loss: 0.021904\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 73300, loss: 0.021873\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich generatentaagegeaod man—all without task-scale unsupmang achieves state-of-the-art performanc \n",
      "----\n",
      "iter 73400, loss: 0.021841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 73500, loss: 0.021800\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 73600, loss: 0.021770\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all withsut and summarization—all without task-schingeachieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 73700, loss: 0.021738\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 73800, loss: 0.021697\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentany re pestion ans unsion, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 73900, loss: 0.021667\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schiue text, achieves state-of-the-art performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 74000, loss: 0.021635\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 74100, loss: 0.021595\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 74200, loss: 0.021565\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-snslation, question answering, and summarization—all without task-sching achieves state-of-the-art p \n",
      "----\n",
      "iter 74300, loss: 0.021534\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 74400, loss: 0.021494\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 74500, loss: 0.021465\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schith gertaped moneanswering, and summarization—all without task-scale unsupmangiaet lace textaansu \n",
      "----\n",
      "iter 74600, loss: 0.021434\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 74700, loss: 0.021394\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and sumarvizerans,eans ruineadind s \n",
      "----\n",
      "iter 74800, loss: 0.021365\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-s comprehension, machine translation, question answering, and \n",
      "----\n",
      "iter 74900, loss: 0.021334\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 75000, loss: 0.021295\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 75100, loss: 0.021266\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- deled lenge task- swering, and summarization—all without task-schine tes coherent paragraphs of tex \n",
      "----\n",
      "iter 75200, loss: 0.021235\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coderudgeandised strance odpudised mon ansart serformance on many language modeling benchmarks, and performs rudimentary reading  \n",
      "----\n",
      "iter 75300, loss: 0.021197\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 75400, loss: 0.021168\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinh anling benchmarks, and performs rudimentary reading comprehension, machine translation, quest \n",
      "----\n",
      "iter 75500, loss: 0.021138\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 75600, loss: 0.021099\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 75700, loss: 0.021071\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, question answering, and summarization—all without task-angu modeling benchmarks, \n",
      "----\n",
      "iter 75800, loss: 0.021041\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 75900, loss: 0.021003\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 76000, loss: 0.020975\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-sswithout task-scale unsupanguage model which generates coherent paragraphs of text, achieves state- \n",
      "----\n",
      "iter 76100, loss: 0.020945\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 76200, loss: 0.020907\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 76300, loss: 0.020879\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-sks sodk- chite-the-art performance on many language modeling benchmarks, and performs rudimentary r \n",
      "----\n",
      "iter 76400, loss: 0.020850\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 76500, loss: 0.020812\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 76600, loss: 0.020785\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schine text, atnsodel which generates coherent paragraphs of  \n",
      "----\n",
      "iter 76700, loss: 0.020755\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 76800, loss: 0.020718\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 76900, loss: 0.020691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmanchieves state-of-the-art performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 77000, loss: 0.020662\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on man, wite-theraohervised language model which generates coh \n",
      "----\n",
      "iter 77100, loss: 0.020625\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 77200, loss: 0.020598\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trangu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 77300, loss: 0.020569\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 77400, loss: 0.020533\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 77500, loss: 0.020506\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieves wanguage madestion answering, and summarization—all without task-schine text,  \n",
      "----\n",
      "iter 77600, loss: 0.020478\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 77700, loss: 0.020441\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 77800, loss: 0.020415\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, aching benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 77900, loss: 0.020387\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 78000, loss: 0.020350\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 78100, loss: 0.020324\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieves mtrehenslation—all without task-schine text, atntoned a large-scale unsupervis \n",
      "----\n",
      "iter 78200, loss: 0.020296\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 78300, loss: 0.020260\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 78400, loss: 0.020234\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schidentaaof tes c s rustior mod machieves state-of-the-art performance on many language modeling be \n",
      "----\n",
      "iter 78500, loss: 0.020207\n",
      "----\n",
      " e’ve trained a large-scage snsl tansumoneanswering, and summarization—all without task-arization—all without task-schine text, atnsage-scale unsupervised language model which generates coherent paragr \n",
      "----\n",
      "iter 78600, loss: 0.020171\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 78700, loss: 0.020145\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsutant ruage-scale unsupervised language model which generates coherent paragraphs of text,  \n",
      "----\n",
      "iter 78800, loss: 0.020118\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 78900, loss: 0.020083\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 79000, loss: 0.020057\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athing benchmarks, and performs rudimentary reansannsinga and performs rudimentary read \n",
      "----\n",
      "iter 79100, loss: 0.020030\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 79200, loss: 0.019995\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 79300, loss: 0.019969\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich generates coherent paragraphs of text, achieves state-of-the-art performance on many language \n",
      "----\n",
      "iter 79400, loss: 0.019942\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 79500, loss: 0.019908\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 79600, loss: 0.019882\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uep, question answering, and summarization—all without task-scale unsupmarization—all witho \n",
      "----\n",
      "iter 79700, loss: 0.019856\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudime-then \n",
      "----\n",
      "iter 79800, loss: 0.019821\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 79900, loss: 0.019796\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un unsupervised language model which generates coherent paragraphs of text, achieves state-of- \n",
      "----\n",
      "iter 80000, loss: 0.019770\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 80100, loss: 0.019735\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehensipe trans, and performs rudimentary reading comprehension, machine translation, q \n",
      "----\n",
      "iter 80200, loss: 0.019711\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many language modeling benchmarks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 80300, loss: 0.019684\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 80400, loss: 0.019650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 80500, loss: 0.019626\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all withoud gand pewites coherent paragraphs of text, achieves state-of-the-art performance on many language modeling \n",
      "----\n",
      "iter 80600, loss: 0.019599\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 80700, loss: 0.019566\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 80800, loss: 0.019541\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un rained w large-scale unsupervised language model which generates coherent paragraphs of tex \n",
      "----\n",
      "iter 80900, loss: 0.019515\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 81000, loss: 0.019482\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 81100, loss: 0.019457\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schide-ed language model which generates coherent paragraphs of text, achieves state-of-the-art perf \n",
      "----\n",
      "iter 81200, loss: 0.019432\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 81300, loss: 0.019398\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 81400, loss: 0.019374\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-sceate-any language modeling benchmarks, and performs rudimentary reading comprehension, machine tra \n",
      "----\n",
      "iter 81500, loss: 0.019348\n",
      "----\n",
      " e’ve trained a large-sch nchieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summar \n",
      "----\n",
      "iter 81600, loss: 0.019315\n",
      "----\n",
      " achieves state-of-the-art performa leransion, machine translation, question answering, and summarization—all without task-scale un u monslation, question ars performs rudimentary reading comprehension \n",
      "----\n",
      "iter 81700, loss: 0.019291\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-sching achieves state-of-the-art performance on many language \n",
      "----\n",
      "iter 81800, loss: 0.019265\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 81900, loss: 0.019232\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answiurform-erks state-of-the-art performance  \n",
      "----\n",
      "iter 82000, loss: 0.019208\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un uragraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 82100, loss: 0.019182\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 82200, loss: 0.019149\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 82300, loss: 0.019125\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-odeling benchmarks, and performs rudimentary reading comprehension, machine translation, question an \n",
      "----\n",
      "iter 82400, loss: 0.019099\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 82500, loss: 0.019066\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 82600, loss: 0.019042\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schichenina uagl machine transladich generates coherent paragraphs of text, achieves state-of-the-ar \n",
      "----\n",
      "iter 82700, loss: 0.019016\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarkslatiormang benchmarks, and \n",
      "----\n",
      "iter 82800, loss: 0.018983\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 82900, loss: 0.018960\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode mrud pragraphs of text, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 83000, loss: 0.018934\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 83100, loss: 0.018902\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 83200, loss: 0.018879\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athing benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 83300, loss: 0.018854\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 83400, loss: 0.018822\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 83500, loss: 0.018799\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-phinerates coherent paragraphs of text, achieves state-of-the-art performance on many language model \n",
      "----\n",
      "iter 83600, loss: 0.018774\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves mtne- ch achmarks, and performs rudimentary reading comprehension, machine translation, que \n",
      "----\n",
      "iter 83700, loss: 0.018742\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 83800, loss: 0.018720\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-oks, and performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 83900, loss: 0.018695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 84000, loss: 0.018664\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 84100, loss: 0.018642\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmachine translation, question answering, and summarization—all without t sk-lswithout tas \n",
      "----\n",
      "iter 84200, loss: 0.018617\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 84300, loss: 0.018586\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 84400, loss: 0.018564\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trat performance on many language modeling benchmarks, and performs rudimentary reading comprehe \n",
      "----\n",
      "iter 84500, loss: 0.018540\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 84600, loss: 0.018510\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 84700, loss: 0.018488\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atyesce  which generates coherent paragraphs of text, achieves state-of-the-art perform \n",
      "----\n",
      "iter 84800, loss: 0.018464\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 84900, loss: 0.018434\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 85000, loss: 0.018412\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieves at task-scale unsupprehension, machine translation, question answering, and su \n",
      "----\n",
      "iter 85100, loss: 0.018389\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 85200, loss: 0.018358\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 85300, loss: 0.018337\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un many lachine translation, question answering, and summarization—all without task-scale un u \n",
      "----\n",
      "iter 85400, loss: 0.018314\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 85500, loss: 0.018284\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 85600, loss: 0.018262\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task- switrmanleaansion, machine translation, question answering,  \n",
      "----\n",
      "iter 85700, loss: 0.018239\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 85800, loss: 0.018210\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 85900, loss: 0.018189\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ansiances states coherent paragraphs of text, achieves state-of-the-art performance on many language \n",
      "----\n",
      "iter 86000, loss: 0.018166\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 86100, loss: 0.018136\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 86200, loss: 0.018115\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schite-the-art performs rudimentary reading comprehension, machine translation, question answering,  \n",
      "----\n",
      "iter 86300, loss: 0.018093\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 86400, loss: 0.018063\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 86500, loss: 0.018043\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achieves ation, machine translation, question answering, and summarization—all without  \n",
      "----\n",
      "iter 86600, loss: 0.018020\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 86700, loss: 0.017991\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 86800, loss: 0.017971\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmathine translation, question answering, and summarization—all without task-sks, hinshaar \n",
      "----\n",
      "iter 86900, loss: 0.017948\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 87000, loss: 0.017919\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 87100, loss: 0.017899\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atnsadel which generates coherent paragraphs of text, achieves state-of-the-art perform \n",
      "----\n",
      "iter 87200, loss: 0.017877\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 87300, loss: 0.017848\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 87400, loss: 0.017828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atrand s mmaraphsteras ludimentaansiaenteres state-of-the-art performance on many langu \n",
      "----\n",
      "iter 87500, loss: 0.017806\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 87600, loss: 0.017778\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 87700, loss: 0.017758\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at, on answering, achieves state-of-the-art performance on many language modeling bench \n",
      "----\n",
      "iter 87800, loss: 0.017736\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 87900, loss: 0.017708\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 88000, loss: 0.017688\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale un rained w leraneheaate-of text, achieves stata-of-the-art performance on many language model \n",
      "----\n",
      "iter 88100, loss: 0.017666\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 88200, loss: 0.017638\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 88300, loss: 0.017619\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schich generanent, grasext, achieves state-of-the-art performance on many language modeling benchmar \n",
      "----\n",
      "iter 88400, loss: 0.017597\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 88500, loss: 0.017569\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 88600, loss: 0.017550\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieves strained a large-scale unsupervised language model which generates coherent pa \n",
      "----\n",
      "iter 88700, loss: 0.017528\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 88800, loss: 0.017501\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 88900, loss: 0.017482\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmathine translation, question answering, and summarization—all without task-schine text,  \n",
      "----\n",
      "iter 89000, loss: 0.017460\n",
      "----\n",
      " e’ve trained a large-scale unsuperviser tarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—allewithout task-scale unsupmarization—all wit \n",
      "----\n",
      "iter 89100, loss: 0.017433\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 89200, loss: 0.017414\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ansian—ila marization—all without task-scale un u maragraphs sadesms rusimg ecosprec, machine transl \n",
      "----\n",
      "iter 89300, loss: 0.017393\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 89400, loss: 0.017365\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 89500, loss: 0.017346\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- dextranslation, question answering, and summarization—all without task-sching achieves state-of-the \n",
      "----\n",
      "iter 89600, loss: 0.017326\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 89700, loss: 0.017298\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 89800, loss: 0.017280\n",
      "----\n",
      "  reaning comprehension, machine translation, question answering, and summarization—all without task-scale unsupmanglahich generates coherent paragraphs of text, achieves state-of-the-art performance o \n",
      "----\n",
      "iter 89900, loss: 0.017259\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 90000, loss: 0.017232\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 90100, loss: 0.017213\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schiteling benchmarks, and performs rudimentary reading comprehension, machine translation, question \n",
      "----\n",
      "iter 90200, loss: 0.017193\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 90300, loss: 0.017166\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 90400, loss: 0.017148\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, aching benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 90500, loss: 0.017127\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 90600, loss: 0.017100\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 90700, loss: 0.017082\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, at tare lahich aglaaioh generates coherent paragraphs of text, achieves state-of-the-ar \n",
      "----\n",
      "iter 90800, loss: 0.017062\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 90900, loss: 0.017035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 91000, loss: 0.017017\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athing -onslation, question answering, and summarization—all without task-scale unsupma \n",
      "----\n",
      "iter 91100, loss: 0.016997\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmprestion answering, and summar \n",
      "----\n",
      "iter 91200, loss: 0.016971\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 91300, loss: 0.016953\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ochedinganswering, and summarization—all without task-schine text, atnsage-scale unsupervised langua \n",
      "----\n",
      "iter 91400, loss: 0.016933\n",
      "----\n",
      " e’ve trained a large-scale unsupervised manguag ainge-scale unsion, machine translation, question answering, and summarization—all without task-schine text, at tage-scale unsion, machine translation,  \n",
      "----\n",
      "iter 91500, loss: 0.016907\n",
      "----\n",
      " achieves state-of-the-art perfoe text, athing comprehension, machine translation, question answering, and summarization—all without task-sks soacs achieves state-of-the-art performance on many languag \n",
      "----\n",
      "iter 91600, loss: 0.016889\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode transummarization—all without task-scale un reinearing benchmarks, and performs rudimentary read \n",
      "----\n",
      "iter 91700, loss: 0.016869\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 91800, loss: 0.016843\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 91900, loss: 0.016825\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ansuag eciormt rks, and performs rudimentary reading comprehension, machine translation, question an \n",
      "----\n",
      "iter 92000, loss: 0.016806\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 92100, loss: 0.016780\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 92200, loss: 0.016762\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trangu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 92300, loss: 0.016743\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 92400, loss: 0.016717\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 92500, loss: 0.016700\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schite-the-art performs rudimentary reading comprehension, machine translation, question answering,  \n",
      "----\n",
      "iter 92600, loss: 0.016680\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 92700, loss: 0.016655\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 92800, loss: 0.016638\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode crat performs rudimentary reading comprehension, machine translation, question answering, and su \n",
      "----\n",
      "iter 92900, loss: 0.016618\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 93000, loss: 0.016593\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 93100, loss: 0.016576\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achieves at pertised language model which generates coherent paragraphs of text, achiev \n",
      "----\n",
      "iter 93200, loss: 0.016557\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 93300, loss: 0.016532\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 93400, loss: 0.016515\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine translation, question answering, and summarization—all without task-scale un performs rudimen \n",
      "----\n",
      "iter 93500, loss: 0.016496\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 93600, loss: 0.016471\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 93700, loss: 0.016454\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-sching achieves state-of-the-art performance on many language modeling benchmarks, and performs rudi \n",
      "----\n",
      "iter 93800, loss: 0.016435\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 93900, loss: 0.016410\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 94000, loss: 0.016393\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-schension, machine translation, question answering, and summa \n",
      "----\n",
      "iter 94100, loss: 0.016375\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 94200, loss: 0.016350\n",
      "----\n",
      " achieves state-of-the-a-o ,arg mod large ension, machine translation, question answering, and summarization—all without task-onsigereization—all without task-schine translation, question answering, an \n",
      "----\n",
      "iter 94300, loss: 0.016333\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, athieg chmarks, and performs rudimentary reading comprehension, machine translation, qu \n",
      "----\n",
      "iter 94400, loss: 0.016315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 94500, loss: 0.016290\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 94600, loss: 0.016274\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmachine translation, question answering, and summarization—all without task-scale unsupma \n",
      "----\n",
      "iter 94700, loss: 0.016255\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 94800, loss: 0.016231\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 94900, loss: 0.016215\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schide-taons of text, achieves state-of-the-art performance on many language modeling benchmarks, an \n",
      "----\n",
      "iter 95000, loss: 0.016196\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 95100, loss: 0.016172\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 95200, loss: 0.016156\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atring bensiany language modeling benchmarks, and performs rudimentary reading comprehe \n",
      "----\n",
      "iter 95300, loss: 0.016138\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 95400, loss: 0.016113\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 95500, loss: 0.016097\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, achieves wtiormsnd sed rt performance on many language modeling benchmarks, and perform \n",
      "----\n",
      "iter 95600, loss: 0.016079\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 95700, loss: 0.016055\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 95800, loss: 0.016039\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-ode trangu modeling benchmarks, and performs rudimentary reading comprehension, machine translation, \n",
      "----\n",
      "iter 95900, loss: 0.016021\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 96000, loss: 0.015998\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 96100, loss: 0.015982\n",
      "----\n",
      "  mermsng benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-schinchmarks, and performs rudimentary reading comprehe \n",
      "----\n",
      "iter 96200, loss: 0.015964\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 96300, loss: 0.015940\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 96400, loss: 0.015924\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scaithe-art performance on many language modeling benchmarks, and performs rudimentary reading compr \n",
      "----\n",
      "iter 96500, loss: 0.015907\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 96600, loss: 0.015883\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 96700, loss: 0.015868\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atnsided a large-scale unsupervised language model which generates coherent paragraphs  \n",
      "----\n",
      "iter 96800, loss: 0.015850\n",
      "----\n",
      " e’ve trained a large-scale unsupervised languahe model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 96900, loss: 0.015827\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 97000, loss: 0.015811\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schins and summarization—all without task-onsian— languagu modeling benchmarks, and performs rudimen \n",
      "----\n",
      "iter 97100, loss: 0.015794\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 97200, loss: 0.015770\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 97300, loss: 0.015755\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmarization—all without task-scale un performs rudimentary reading comprehension, machine  \n",
      "----\n",
      "iter 97400, loss: 0.015738\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 97500, loss: 0.015715\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 97600, loss: 0.015699\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schinchmarks, and performs rudimentary reading comprehension, machine translation, question answerin \n",
      "----\n",
      "iter 97700, loss: 0.015682\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 97800, loss: 0.015659\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 97900, loss: 0.015644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupaneaension, machine translation, question answering, and summarization—all without task-s \n",
      "----\n",
      "iter 98000, loss: 0.015627\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 98100, loss: 0.015604\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 98200, loss: 0.015589\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-schine text, atnswe s-of text, atuing benchmarks, and performs rudimentary reading comprehension, ma \n",
      "----\n",
      "iter 98300, loss: 0.015572\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 98400, loss: 0.015549\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 98500, loss: 0.015534\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-vdilerates coherent paragraphs of text, achieves state-of-the-art performance on many language model \n",
      "----\n",
      "iter 98600, loss: 0.015517\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 98700, loss: 0.015495\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 98800, loss: 0.015480\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task- dnped language model which generates coherent paragraphs of text, achieves state-of-the-art perform \n",
      "----\n",
      "iter 98900, loss: 0.015463\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 99000, loss: 0.015441\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 99100, loss: 0.015426\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-achine trans ation, question answering, and summarization—all without task-scale-scale unsupervised  \n",
      "----\n",
      "iter 99200, loss: 0.015409\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 99300, loss: 0.015387\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 99400, loss: 0.015372\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-onsuany wansyaloherent paragraphs of text, achieves state-of-the-art performance on many language mo \n",
      "----\n",
      "iter 99500, loss: 0.015356\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 99600, loss: 0.015334\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task- \n",
      "----\n",
      "iter 99700, loss: 0.015319\n",
      "----\n",
      "  reading comprehension, machine translation, question answering, and summarization—all without task-scale unsupmachine translation, question answering, and summarization—all without task-ode transuman \n",
      "----\n",
      "iter 99800, loss: 0.015303\n",
      "----\n",
      " e’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary \n",
      "----\n",
      "iter 99900, loss: 0.015281\n",
      "----\n",
      " achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all wite-thout ta \n",
      "----\n",
      "iter 100000, loss: 0.015266\n"
     ]
    }
   ],
   "source": [
    "# %load rnn.py\n",
    "\"\"\"\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "BSD License\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "\n",
    "  def lossFun(inputs, targets, hprev):\n",
    "    \"\"\"\n",
    "    inputs,targets are both list of integers.\n",
    "    hprev is Hx1 array of initial hidden state\n",
    "    returns the loss, gradients on model parameters, and last hidden state\n",
    "    \"\"\"\n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    # forward pass\n",
    "    for t in range(len(inputs)):\n",
    "      xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "      xs[t][inputs[t]] = 1\n",
    "      hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "      ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "      ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "      loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "    # backward pass: compute gradients going backwards\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "      dy = np.copy(ps[t])\n",
    "      dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "      dWhy += np.dot(dy, hs[t].T)\n",
    "      dby += dy\n",
    "      dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "      dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "      dbh += dhraw\n",
    "      dWxh += np.dot(dhraw, xs[t].T)\n",
    "      dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "      dhnext = np.dot(Whh.T, dhraw)\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "      np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "  def sample(h, seed_ix, n):\n",
    "    \"\"\" \n",
    "    sample a sequence of integers from the model \n",
    "    h is memory state, seed_ix is seed letter for first time step\n",
    "    \"\"\"\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    for t in range(n):\n",
    "      h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "      y = np.dot(Why, h) + by\n",
    "      p = np.exp(y) / np.sum(np.exp(y))\n",
    "      ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "      x = np.zeros((vocab_size, 1))\n",
    "      x[ix] = 1\n",
    "      ixes.append(ix)\n",
    "    return ixes\n",
    "\n",
    "\n",
    "  def sample_top3(h, seed_ix):\n",
    "    \"\"\" \n",
    "    output the top3 probable next letters \n",
    "    h is memory state, seed_ix is seed letter\n",
    "    \"\"\"\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ixes = np.random.choice(range(vocab_size),3 , p=p.ravel())\n",
    "    return ixes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # data I/O\n",
    "  data = open('train_input.txt', 'r').read() # should be simple plain text file\n",
    "  chars = list(set(data))\n",
    "  data_size, vocab_size = len(data), len(chars)\n",
    "  print ('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "  char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "  ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "  # hyperparameters\n",
    "  hidden_size = 100 # size of hidden layer of neurons\n",
    "  seq_length = 25 # number of steps to unroll the RNN for\n",
    "  learning_rate = 1e-1\n",
    "\n",
    "  # model parameters\n",
    "  Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "  Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "  Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "  bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "  by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "  n, p = 0, 0\n",
    "  mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "  smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "  while n<=100000:\n",
    "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "    if p+seq_length+1 >= len(data) or n == 0: \n",
    "      hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "      p = 0 # go from start of data\n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "    # sample from the model now and then\n",
    "    if n % 100 == 0:\n",
    "      sample_ix = Model.sample(hprev, inputs[0], 200)\n",
    "      txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "      print('----\\n %s \\n----' % (txt, ))\n",
    "\n",
    "    # forward seq_length characters through the net and fetch gradient\n",
    "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = Model.lossFun(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if n % 100 == 0: \n",
    "      print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "    \n",
    "    # perform parameter update with Adagrad\n",
    "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                  [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "      mem += dparam * dparam\n",
    "      param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "    p += seq_length # move data pointer\n",
    "    n += 1 # iteration counter\n",
    "  \n",
    "  f_pred = open(\"pred.txt\", \"w\")\n",
    "\n",
    "  with open('test_input.txt') as f:\n",
    "    for line in f:\n",
    "      line = line.split()\n",
    "      char = list(line[len(line)-1])\n",
    "      i = char[len(char)-1] #get last character of input line\n",
    "      sample_ix = Model.sample_top3(hprev, char_to_ix[i])\n",
    "      txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "      f_pred.write(txt + '\\n')\n",
    "  f_pred.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
